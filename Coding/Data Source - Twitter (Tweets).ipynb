{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dde511c",
   "metadata": {},
   "source": [
    "- need to make a time function to query data\n",
    "- add query for both ethereum and bitcoin ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import tweepy\n",
    "import configparser\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334a7b1",
   "metadata": {},
   "source": [
    "# Retrieving Twitter Data using Tweepy with Academic Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e534c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading API token and secret\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df525cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting variable from config.ini file\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']\n",
    "bearer_token = config['twitter']['bearer_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0041c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting authetication\n",
    "#OAuth is an open-standard Authorization protocol or framework that provides applications the ability for \"secure designated access\"\n",
    "#OAuth doesn't share password data but instead uses authorizations tokens to prove an identitybetween consumers and providers\n",
    "#OAuth is an authorizations protocal that allows you to approve one application interacting with another on behalf without giving away your password\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "#Generating an instance of Client with access full archieve from Academic Access\n",
    "client = tweepy.Client(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ae674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to retrieve the Tweet data using the Twitter API with Academic Access\n",
    "\n",
    "def get_data_from_tweet(response):\n",
    "    '''\n",
    "    get_data_from_tweet(response)\n",
    "        response: Responce data from Get Request containing tweet_id and text\n",
    "        Function get status of tweet_id to retrieve username,description,location, #following, #followers and  #totaltweets of user and full_text, retweetcount, hashtags and time created of the tweet_id.\n",
    "    :return:\n",
    "        Dataframe containing: username, description, location, following, followers, totaltweets, retweetcount, text, hashtags and created_at\n",
    "    '''\n",
    "\n",
    "    #DataFrame generated to store User and Tweet information\n",
    "    db = pd.DataFrame(columns=[\n",
    "        'tweed_id',\n",
    "        'username',\n",
    "        'description',\n",
    "        'location',\n",
    "        'following',\n",
    "        'followers',\n",
    "        'totaltweets',\n",
    "        'retweetcount',\n",
    "        'text',\n",
    "        'hashtags',\n",
    "        'created_at'])\n",
    "\n",
    "    #Getting information from response variable input\n",
    "    for tweet in response.data:\n",
    "        tweet_data = api.get_status(tweet.id,tweet_mode='extended')\n",
    "        username = tweet_data.user.screen_name\n",
    "        description = tweet_data.user.description\n",
    "        location = tweet_data.user.location\n",
    "        following = tweet_data.user.friends_count\n",
    "        followers = tweet_data.user.followers_count\n",
    "        totaltweets = tweet_data.user.statuses_count\n",
    "        retweetcount = tweet_data.retweet_count\n",
    "        text = tweet_data.full_text\n",
    "        hashtags = tweet_data.entities['hashtags']\n",
    "        created_at = tweet_data.created_at\n",
    "\n",
    "        hashtext = list()\n",
    "        for j in range(0, len(hashtags)):\n",
    "            hashtext.append(hashtags[j]['text'])\n",
    "\n",
    "        tweet_summary = [tweet, username,description,location,following,followers,totaltweets,retweetcount,text,hashtext,created_at]\n",
    "        db.loc[len(db)] = tweet_summary\n",
    "\n",
    "    return db #return CSV format directly\n",
    "#initializing tokens\n",
    "if __name__ == '__main__':\n",
    "        consumer_key = api_key\n",
    "        consumer_secret = api_key_secret\n",
    "        access_key = access_token\n",
    "        access_secret = access_token_secret\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_key, access_secret)\n",
    "        client = tweepy.Client(bearer_token=bearer_token,wait_on_rate_limit=True) #will be used later when function is generalised to take query input\n",
    "        api = tweepy.API(auth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input for full archieve query\n",
    "This endpoint can deliver up to 500 Tweets per request in reverse-chronological order, and pagination tokens are provided for paging through large sets of matching Tweets.\n",
    "https://developer.twitter.com/en/docs/twitter-api/tweets/search/introduction\n",
    "\n",
    "Datetime values are always returned in UTC time (as indicated by the Z at the end of the datetime value.) Datetimes may be specified in any timezone in a POST or PUT command using the ISO 8601 standard format for timezone. Time is represented using a subset of ISO-8601. More specifically, the strptime string for our date format is \"%Y-%m-%dT%l:%M:%S%z\". The timezone of the advertiserâ€™s account determines the actual time that the official billing numbers are frozen.\n",
    "https://developer.twitter.com/en/docs/twitter-ads-api/timezones\n",
    "\n",
    "''' \n",
    "\n",
    "query = 'bitcoin OR #bitcoin  lang:en -is:retweet'\n",
    "start_time = '2021-01-25T00:00:00Z'\n",
    "stop_time = '2021-01-26T00:00:00Z'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f90d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching Twitter Archieve for the parameters defined above\n",
    "\n",
    "response = client.search_all_tweets(query=query,max_results=100,start_time=start_time, end_time=stop_time)\n",
    "result = get_data_from_tweet(response=response)\n",
    "result.to_csv('Datasets/Tweet Data/academic_{}.csv'.format(str(datetime.datetime.now())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving results\n",
    "\n",
    "result = get_data_from_tweet(response=response)\n",
    "result.to_csv('Datasets/Tweet Data/academic_{}.csv'.format(str(datetime.datetime.now())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a32d8e",
   "metadata": {},
   "source": [
    "## Testing API connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15cf371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search keyword\n",
    "keyword = 'bitcoin'\n",
    "\n",
    "#Data since search yyyy-mm-dd\n",
    "date_since = '2022-01-31'\n",
    "\n",
    "#Number of Tweets, integer\n",
    "numtweets = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweepy.Cursor(api.search_tweets,label='FullArchive' , q = keyword, since_id=date_since, lang=\"en\", tweet_mode=\"extended\").items(numtweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = [tweet for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b1c42",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tweets_list[2].user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66f10d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 7\n",
    "print(tweets_list[index].full_text)\n",
    "print(tweets_list[index].created_at)\n",
    "print(tweets_list[index].user.created_at)\n",
    "print(tweets_list[index].metadata)\n",
    "#print(tweets_list[index].s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_status(1523305075463970818,tweet_mode=\"extended\").created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_at = api.get_status(1523305075463970818,tweet_mode=\"extended\").created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac51ca9d",
   "metadata": {},
   "source": [
    "# Sample Code from GeeksforGeeks to retrieve Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f5e23",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### https://www.geeksforgeeks.org/extracting-tweets-containing-a-particular-hashtag-using-python/\n",
    "# Python Script to Extract tweets of a\n",
    "# particular Hashtag using Tweepy and Pandas\n",
    "\n",
    "# import modules\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "\n",
    "# function to display data of each tweet\n",
    "def printtweetdata(n, ith_tweet):\n",
    "        print()\n",
    "        print(f\"Tweet {n}:\")\n",
    "        print(f\"Username:{ith_tweet[0]}\")\n",
    "        print(f\"Description:{ith_tweet[1]}\")\n",
    "        print(f\"Location:{ith_tweet[2]}\")\n",
    "        print(f\"Following Count:{ith_tweet[3]}\")\n",
    "        print(f\"Follower Count:{ith_tweet[4]}\")\n",
    "        print(f\"Total Tweets:{ith_tweet[5]}\")\n",
    "        print(f\"Retweet Count:{ith_tweet[6]}\")\n",
    "        print(f\"Tweet Text:{ith_tweet[7]}\")\n",
    "        print(f\"Hashtags Used:{ith_tweet[8]}\")\n",
    "\n",
    "\n",
    "# function to perform data extraction\n",
    "def scrape(words, date_since, numtweet):\n",
    "\n",
    "        # Creating DataFrame using pandas\n",
    "        db = pd.DataFrame(columns=['username',\n",
    "                                'description',\n",
    "                                'location',\n",
    "                                'following',\n",
    "                                'followers',\n",
    "                                'totaltweets',\n",
    "                                'retweetcount',\n",
    "                                'text',\n",
    "                                'hashtags',\n",
    "                                'created_at'])\n",
    "\n",
    "        # We are using .Cursor() to search\n",
    "        # through twitter for the required tweets.\n",
    "        # The number of tweets can be\n",
    "        # restricted using .items(number of tweets)\n",
    "        tweets = tweepy.Cursor(api.search_tweets,\n",
    "                            words, lang=\"en\",\n",
    "                            since_id=date_since,\n",
    "                            tweet_mode='extended').items(numtweet)\n",
    "        print(tweets.num_tweets)\n",
    "\n",
    "        # .Cursor() returns an iterable object. Each item in\n",
    "        # the iterator has various attributes\n",
    "        # that you can access to\n",
    "        # get information about each tweet\n",
    "        list_tweets = [tweet for tweet in tweets]\n",
    "        print(list_tweets)\n",
    "\n",
    "        # Counter to maintain Tweet Count\n",
    "        i = 1\n",
    "\n",
    "        # we will iterate over each tweet in the\n",
    "        # list for extracting information about each tweet\n",
    "        for tweet in list_tweets:\n",
    "                username = tweet.user.screen_name\n",
    "                description = tweet.user.description\n",
    "                location = tweet.user.location\n",
    "                following = tweet.user.friends_count\n",
    "                followers = tweet.user.followers_count\n",
    "                totaltweets = tweet.user.statuses_count\n",
    "                retweetcount = tweet.retweet_count\n",
    "                hashtags = tweet.entities['hashtags']\n",
    "                created_at = tweet.created_at\n",
    "\n",
    "                # Retweets can be distinguished by\n",
    "                # a retweeted_status attribute,\n",
    "                # in case it is an invalid reference,\n",
    "                # except block will be executed\n",
    "                try:\n",
    "                        text = tweet.retweeted_status.full_text\n",
    "                except AttributeError:\n",
    "                        text = tweet.full_text\n",
    "                hashtext = list()\n",
    "                for j in range(0, len(hashtags)):\n",
    "                        hashtext.append(hashtags[j]['text'])\n",
    "\n",
    "                # Here we are appending all the\n",
    "                # extracted information in the DataFrame\n",
    "                ith_tweet = [username, description,\n",
    "                            location, following,\n",
    "                            followers, totaltweets,\n",
    "                            retweetcount, text, hashtext, created_at]\n",
    "                db.loc[len(db)] = ith_tweet\n",
    "\n",
    "                # Function call to print tweet data on screen\n",
    "                printtweetdata(i, ith_tweet)\n",
    "                i = i+1\n",
    "                filename = 'test_scraped_tweets.csv'\n",
    "\n",
    "        # we will save our database as a CSV file.\n",
    "        #db.to_csv(f\"Datasets/{filename}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "        # Enter your own credentials obtained\n",
    "        # from your developer account\n",
    "        consumer_key = api_key\n",
    "        consumer_secret = api_key_secret\n",
    "        access_key = access_token\n",
    "        access_secret = access_token_secret\n",
    "\n",
    " \n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_key, access_secret)\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        # Enter Hashtag and initial date\n",
    "        print(\"Enter Twitter HashTag to search for\")\n",
    "        words = input()\n",
    "        print(\"Enter Date since The Tweets are required in yyyy-mm--dd\")\n",
    "        date_since = input()\n",
    "\n",
    "        # number of tweets you want to extract in one run\n",
    "        numtweet = 10\n",
    "        scrape(words, date_since, numtweet)\n",
    "        print('Scraping has completed!')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d325771",
   "metadata": {},
   "source": [
    "### Getting Tweets between [06/01/2022 - 15/07/2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = 'bitcoin OR #bitcoin  lang:en -is:retweets'\n",
    "dates_day = pd.date_range(start='2022-06-01',end='15/07/2022',freq='D')\n",
    "dates_min = pd.date_range(start='2022-06-01',end='15/07/2022',freq='T')\n",
    "#dates_min = pd.DataFrame(dates_min,columns=['Dates'])\n",
    "len(dates_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_per_day = pd.read_csv('count.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.log import error\n",
    "\n",
    "result = pd.DataFrame()\n",
    "query = 'bitcoin OR #bitcoin  lang:en -is:retweet'\n",
    "counter = 0\n",
    "#for i in range(len(dates_min)-1):\n",
    "for i in range(5761,len(dates_min)-1):\n",
    "    gate_1 = False\n",
    "    gate_2 = False\n",
    "    while gate_1 ==False:\n",
    "        try:\n",
    "            start_time = '{}Z'.format(dates_min[i].isoformat())\n",
    "            end_time = '{}Z'.format(dates_min[i+1].isoformat())\n",
    "            max_count = count_per_day.iloc[np.mod(i,1440)].values[0]\n",
    "            #print(start_time)\n",
    "            #print(end_time)\n",
    "            print('Index: {}'.format(i))\n",
    "\n",
    "            response = client.search_all_tweets(query=query,max_results=15,start_time=start_time, end_time=end_time)\n",
    "            output = get_data_from_tweet(response=response)\n",
    "\n",
    "            counter = counter + len(output.index)\n",
    "\n",
    "            print('Tweet Count: {}'.format(counter))\n",
    "\n",
    "            result = [result,output]\n",
    "            result = pd.concat(result,ignore_index=True)\n",
    "            if i!=0 and np.mod(i,1440)==0:\n",
    "                result.to_csv('Datasets/Tweet Data/academic_{}_{}.csv'.format(str(datetime.datetime.now()),i))\n",
    "                result = pd.DataFrame()\n",
    "            gate_1 = True\n",
    "            time.sleep(2)\n",
    "\n",
    "        except Exception as e:\n",
    "            if gate_2 == False:     \n",
    "                result.to_csv('Datasets/Tweet Data/academic_{}_{}.csv'.format(str(datetime.datetime.now()),i))\n",
    "                gate_2 =True\n",
    "            #print(error)\n",
    "            print(\"Exception Occured while code Execution: \"+ str(e))\n",
    "            time.sleep(120)\n",
    "\n",
    "\n",
    "result.to_csv('Datasets/Tweet Data/academic_{}_{}.csv'.format(str(datetime.datetime.now()),i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching Twitter Archieve for the parameters defined above\n",
    "response = client.search_all_tweets(query=query,max_results=77,start_time='2022-06-01T00:00:00Z', end_time='2022-06-01T00:01:00Z')\n",
    "result = get_data_from_tweet(response=response)\n",
    "result.to_csv('Datasets/Tweet Data/academic_{}.csv'.format(str(datetime.datetime.now())))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
