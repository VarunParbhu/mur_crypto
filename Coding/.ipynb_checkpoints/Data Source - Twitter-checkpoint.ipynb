{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b82d9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8e534c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "df525cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading configs required\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8dd019b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting authetication\n",
    "auth = tweepy.OAuthHandler(api_key,api_key_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ede22863",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "361f5e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Twitter HashTag to search for\n",
      "bitcoin\n",
      "Enter Date since The Tweets are required in yyyy-mm--dd\n",
      "2022-01-15\n",
      "Scraping has completed!\n"
     ]
    }
   ],
   "source": [
    "# Python Script to Extract tweets of a\n",
    "# particular Hashtag using Tweepy and Pandas\n",
    "\n",
    "# import modules\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "\n",
    "# function to display data of each tweet\n",
    "def printtweetdata(n, ith_tweet):\n",
    "        print()\n",
    "        print(f\"Tweet {n}:\")\n",
    "        print(f\"Username:{ith_tweet[0]}\")\n",
    "        print(f\"Description:{ith_tweet[1]}\")\n",
    "        print(f\"Location:{ith_tweet[2]}\")\n",
    "        print(f\"Following Count:{ith_tweet[3]}\")\n",
    "        print(f\"Follower Count:{ith_tweet[4]}\")\n",
    "        print(f\"Total Tweets:{ith_tweet[5]}\")\n",
    "        print(f\"Retweet Count:{ith_tweet[6]}\")\n",
    "        print(f\"Tweet Text:{ith_tweet[7]}\")\n",
    "        print(f\"Hashtags Used:{ith_tweet[8]}\")\n",
    "\n",
    "\n",
    "# function to perform data extraction\n",
    "def scrape(words, date_since, numtweet):\n",
    "\n",
    "        # Creating DataFrame using pandas\n",
    "        db = pd.DataFrame(columns=['username',\n",
    "                                'description',\n",
    "                                'location',\n",
    "                                'following',\n",
    "                                'followers',\n",
    "                                'totaltweets',\n",
    "                                'retweetcount',\n",
    "                                'text',\n",
    "                                'hashtags',\n",
    "                                'created_at'])\n",
    "\n",
    "        # We are using .Cursor() to search\n",
    "        # through twitter for the required tweets.\n",
    "        # The number of tweets can be\n",
    "        # restricted using .items(number of tweets)\n",
    "        tweets = tweepy.Cursor(api.search_tweets,\n",
    "                            words, lang=\"en\",\n",
    "                            since_id=date_since,\n",
    "                            tweet_mode='extended').items(numtweet)\n",
    "\n",
    "\n",
    "        # .Cursor() returns an iterable object. Each item in\n",
    "        # the iterator has various attributes\n",
    "        # that you can access to\n",
    "        # get information about each tweet\n",
    "        list_tweets = [tweet for tweet in tweets]\n",
    "\n",
    "        # Counter to maintain Tweet Count\n",
    "        i = 1\n",
    "\n",
    "        # we will iterate over each tweet in the\n",
    "        # list for extracting information about each tweet\n",
    "        for tweet in list_tweets:\n",
    "                username = tweet.user.screen_name\n",
    "                description = tweet.user.description\n",
    "                location = tweet.user.location\n",
    "                following = tweet.user.friends_count\n",
    "                followers = tweet.user.followers_count\n",
    "                totaltweets = tweet.user.statuses_count\n",
    "                retweetcount = tweet.retweet_count\n",
    "                hashtags = tweet.entities['hashtags']\n",
    "                created_at = tweet.created_at\n",
    "\n",
    "                # Retweets can be distinguished by\n",
    "                # a retweeted_status attribute,\n",
    "                # in case it is an invalid reference,\n",
    "                # except block will be executed\n",
    "                try:\n",
    "                        text = tweet.retweeted_status.full_text\n",
    "                except AttributeError:\n",
    "                        text = tweet.full_text\n",
    "                hashtext = list()\n",
    "                for j in range(0, len(hashtags)):\n",
    "                        hashtext.append(hashtags[j]['text'])\n",
    "\n",
    "                # Here we are appending all the\n",
    "                # extracted information in the DataFrame\n",
    "                ith_tweet = [username, description,\n",
    "                            location, following,\n",
    "                            followers, totaltweets,\n",
    "                            retweetcount, text, hashtext, created_at]\n",
    "                db.loc[len(db)] = ith_tweet\n",
    "\n",
    "                # Function call to print tweet data on screen\n",
    "                #printtweetdata(i, ith_tweet)\n",
    "                i = i+1\n",
    "                filename = 'test_scraped_tweets.csv'\n",
    "\n",
    "        # we will save our database as a CSV file.\n",
    "        db.to_csv(f\"Datasets/{filename}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "        # Enter your own credentials obtained\n",
    "        # from your developer account\n",
    "        consumer_key = api_key\n",
    "        consumer_secret = api_key_secret\n",
    "        access_key = access_token\n",
    "        access_secret = access_token_secret\n",
    "\n",
    "\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_key, access_secret)\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        # Enter Hashtag and initial date\n",
    "        print(\"Enter Twitter HashTag to search for\")\n",
    "        words = input()\n",
    "        print(\"Enter Date since The Tweets are required in yyyy-mm--dd\")\n",
    "        date_since = input()\n",
    "\n",
    "        # number of tweets you want to extract in one run\n",
    "        numtweet = 1000\n",
    "        scrape(words, date_since, numtweet)\n",
    "        print('Scraping has completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
