{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create function to apply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import datetime\n",
    "import demoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import spacy\n",
    "from matplotlib import pyplot as plt\n",
    "#from spacy.language import Language \n",
    "#from spacy_langdetect import LanguageDetector\n",
    "#from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all file paths in the Tweet Data folder \n",
    "data_path = os.listdir('Datasets/Tweet Data')\n",
    "data_path.sort()\n",
    "data_path = ['Datasets/Tweet Data/{}'.format(file) for file in data_path]\n",
    "data_path = pd.DataFrame(data_path,columns=['File Path'])\n",
    "\n",
    "# Getting the counter from the file name in to the dataframe\n",
    "try:\n",
    "    data_path = pd.concat([data_path,pd.DataFrame(data_path['File Path'].str.split(r'_',expand=True)[2])],axis=1)\n",
    "    data_path = pd.concat([data_path,data_path[2].str.split(r'\\.',expand=True)],axis=1,)\n",
    "    data_path = data_path[['File Path',0]]\n",
    "    data_path.columns = ['File Path', 'Counter']\n",
    "    data_path['Counter'] = data_path['Counter'].apply(lambda x: int(x))\n",
    "   \n",
    "except:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the shape of the relevant excel sheet\n",
    "\n",
    "from distutils.log import error\n",
    "day = 0\n",
    "total = 0\n",
    "for i,file in enumerate(data_path.values):\n",
    "    if np.mod(file[1],1440)==0:\n",
    "        try:\n",
    "            day +=1\n",
    "            print(day,i,file[1],pd.read_csv(file[0],engine='python',index_col=0).shape)\n",
    "            total += pd.read_csv(file[0],engine='python',index_col=0).shape[0]\n",
    "            #shutil.copy(file[0],'Datasets/Daily Tweet Data/{}.csv'.format(str(datetime.datetime.now())))\n",
    "        except error as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove @[someone] - Done\n",
    "- Remove string 'RT'- Done\n",
    "- Remove new line - Done\n",
    "- Remove punctuation (Remove # only; keep the string) - Done\n",
    "- Remove links to http - Done\n",
    "- Replace emojis by description - Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_tweet (text):\n",
    "    #Remove all links starting with http...\n",
    "    text = re.sub('https?:\\/\\/.*[\\r\\n]*','',text)\n",
    "    #Remove RT\n",
    "    text = re.sub('^RT[\\s]+','',text)\n",
    "    #Remove @[User]\n",
    "    text = re.sub('@[^ ]+', '', text)\n",
    "    #Remove Punctuation first\n",
    "    text = text.translate(str.maketrans('','', string.punctuation))\n",
    "    #Convert text to lower case\n",
    "    text = text.lower()\n",
    "    #Removing any number\n",
    "    #text = re.sub('[0-9]+ ','',text)\n",
    "    #Removing any number with text\n",
    "    #text = re.sub('[0-9]+.+\\s*','',text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text).strip()\n",
    "    #Remove new line\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    #Replace emojis with description\n",
    "    text = demoji.replace_with_desc(text,sep=' ')\n",
    "    #Reducing whitespaces to one everywhere\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all file paths in the Tweet Data folder \n",
    "data_path_daily = os.listdir('Datasets/Daily Tweet Data')\n",
    "data_path_daily.sort()\n",
    "data_path_daily = ['Datasets/Daily Tweet Data/{}'.format(file) for file in data_path_daily]\n",
    "data_path_daily = pd.DataFrame(data_path_daily,columns=['File Path'])\n",
    "\n",
    "# Getting the counter from the file name in to the dataframe\n",
    "# try:\n",
    "#     data_path = pd.concat([data_path,pd.DataFrame(data_path['File Path'].str.split(r'_',expand=True)[2])],axis=1)\n",
    "#     data_path = pd.concat([data_path,data_path[2].str.split(r'\\.',expand=True)],axis=1,)\n",
    "#     data_path = data_path[['File Path',0]]\n",
    "#     data_path.columns = ['File Path', 'Counter']\n",
    "#     data_path['Counter'] = data_path['Counter'].apply(lambda x: int(x))\n",
    "   \n",
    "# except:\n",
    "#     print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.DataFrame()\n",
    "for i,file in enumerate(data_path_daily['File Path']):\n",
    "    data = pd.read_csv(file,engine='python',index_col=0)\n",
    "    data['tweed_id'] = data['tweed_id'].astype(str)\n",
    "    data['clean_tweet'] = data['tweed_id'].apply(pre_process_tweet)\n",
    "    clean_data = pd.concat([clean_data,data], ignore_index=True,axis=0)\n",
    "\n",
    "clean_data.to_csv('clean_tweets.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lang_detector(nlp, name):\n",
    "#    return LanguageDetector()\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Language.factory(\"language_detector\", func = get_lang_detector)\n",
    "# nlp.add_pipe('language_detector', last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tweet_language(tweet):\n",
    "#     document = nlp(tweet)\n",
    "#     return document._.language['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['lang'] = data['clean_tweet'].apply(tweet_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(height = data['lang'].value_counts().values[:10],x=data['lang'].value_counts().index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['lang'].value_counts().index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mur_crypto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc9f29d5f2d7b27ff6a84ea5fe88a58c09ecfb01691ae484020498e4c6bdd330"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
