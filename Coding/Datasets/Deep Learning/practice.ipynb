{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot and Cold Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 0.5\n",
    "goal_pred = 0.8\n",
    "weight = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_h_c(input,weight):\n",
    "    return input*weight\n",
    "\n",
    "def error_se(pred,goal_pred):\n",
    "    return (pred - goal_pred)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_h_c(input,weight)\n",
    "error = error_se(pred,goal_pred)\n",
    "\n",
    "for i in range(1101):\n",
    "    weight_delta = 0.001\n",
    "    weight_more = weight + weight_delta\n",
    "    weight_less = weight - weight_delta\n",
    "    \n",
    "    error_h = error_se(pred_h_c(input,weight_more),goal_pred)\n",
    "    error_c = error_se(pred_h_c(input,weight_less),goal_pred)\n",
    "\n",
    "    if (error_h <= error_c):\n",
    "        weight = weight_more\n",
    "    else:\n",
    "        weight = weight_less\n",
    "    \n",
    "    #print('Error: {}  Predicition: {}'.format(error_se(pred_h_c(input,weight),goal_pred),pred_h_c(input,weight)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 2\n",
    "goal_pred = 0.8\n",
    "weight = 0.5\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_h_c(input,weight)\n",
    "error = error_se(pred,input)\n",
    "\n",
    "for i in range (50):\n",
    "    raw_error = pred - goal_pred\n",
    "    delta = (raw_error)*input ## accounts for Direction and Amount, Pure Error, Scaling Negative Reversal and Stopping\n",
    "    weight -= delta*alpha\n",
    "    pred = pred_h_c(input,weight)\n",
    "    error = error_se(pred,goal_pred)\n",
    "    #print('Error: {}  Predicition: {}'.format(error_se(pred_h_c(input,weight),goal_pred),pred_h_c(input,weight)))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "toes = [8.5, 9.5, 9.9, 9.0] \n",
    "wlrec = [0.65, 0.8, 0.8, 0.9] \n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "#Target\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_grad_desc (input, weight):\n",
    "    return np.dot(input,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(input) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with Multiple Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = np.array([toes[0],wlrec[0],nfans[0]])\n",
    "weight = np.array([0.1, 0.2, -.1])\n",
    "alpha = 0.01\n",
    "\n",
    "output = win_or_lose_binary[1]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    pred = pred_grad_desc(input,weight)\n",
    "    delta = pred - output\n",
    "    error = delta**2\n",
    "\n",
    "    weight_delta = delta\n",
    "    weight = weight - weight_delta*alpha\n",
    "\n",
    "    #print('Error: {}  Predicition: {}'.format(error,pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with Multiple Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlrec = [0.65, 1.0, 1.0, 0.9] #win percentage for games\n",
    "\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win = [1,1,0,1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "weight = np.array([0.3, 0.2, 0.9])\n",
    "alpha = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_ele_mult(number,vector):\n",
    "    output = [0,0,0]\n",
    "    assert(len(number)==len(vector))\n",
    "    for i in range(len(number)):\n",
    "        output[i] = number[i]*vector[i]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_ele_mult_num(number,vector):\n",
    "    output = [0,0,0]\n",
    "    assert(len(output)==len(vector))\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = number*vector[i]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = wlrec[0]\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "for epoch in range(100):\n",
    "    pred = weight*input\n",
    "\n",
    "    delta = [0,0,0]\n",
    "    error = [0,0,0]\n",
    "\n",
    "    for i in range(len(true)):\n",
    "        delta[i] = pred[i] - true[i]\n",
    "        error[i] = (delta[i])**2\n",
    "        \n",
    "    weight_delta = scalar_ele_mult_num(input,delta)\n",
    "    \n",
    "    weight -= scalar_ele_mult_num(alpha,weight_delta)\n",
    "    #print(\"Weights:\" + str(weight))\n",
    "    #print(\"Error:\" + str(error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with Multiple Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    [0.1, 0.1, -0.3],\n",
    "    [0.1, 0.2, 0.0],\n",
    "    [0.0, 1.3, 0.1]\n",
    " ]\n",
    "\n",
    "## Inputs\n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0] \n",
    "lrec = [0.65,0.8, 0.8, 0.9] \n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "## Outputs\n",
    "\n",
    "hurt = [0.1, 0.0, 0.0, 0.1] \n",
    "win =[1,1,0,1] \n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_mat_mult(vector, matrix):\n",
    "    output = [0,0,0]\n",
    "    assert(len(vector)==len(matrix))\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = np.dot(vector,matrix[i])\n",
    "    return output\n",
    "\n",
    "def outer_prod(vec_a,vec_b):\n",
    "    assert(len(vec_a)==len(vec_b))\n",
    "    output = np.zeros([3,3])\n",
    "    for i in range(len(vec_a)):\n",
    "        for j in range(len(vec_b)):\n",
    "            output[i,j] = vec_a[i]*vec_b[j]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [toes[0], lrec[0],nfans[0]]\n",
    "true = [hurt[0],win[0],sad[0]]\n",
    "alpha = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    pred = vec_mat_mult(input,weights)\n",
    "    delta = [0,0,0]\n",
    "    error = [0,0,0]\n",
    "    for i in range(output):\n",
    "        delta[i] = pred[i] - true[i]\n",
    "        error[i] =delta[i]**2\n",
    "    \n",
    "    weight_delta = outer_prod(input,delta)\n",
    "    \n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights)):\n",
    "            weights[i][j] -= alpha*weight_delta[i][j]\n",
    "\n",
    "    #print(\"Weights:\" + str(weight))\n",
    "    #print(\"Error:\" + str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0.5,0.48,-0.7]) \n",
    "alpha = 0.1\n",
    "\n",
    "streetlights = np.array([\n",
    "    [ 1, 0, 1 ], \n",
    "    [ 0, 1, 1 ],\n",
    "    [ 0, 0, 1 ], \n",
    "    [ 1, 1, 1 ], \n",
    "    [ 0, 1, 1 ],\n",
    "    [ 1, 0, 1 ]\n",
    "])\n",
    "\n",
    "walk_vs_stop = np.array([ 0, 1, 0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = streetlights\n",
    "output = walk_vs_stop\n",
    "\n",
    "weight = weights\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    total_error = 0\n",
    "    for row in range(len(input)):\n",
    "        pred = np.dot(input[row],weight)\n",
    "        delta = pred - output[row]\n",
    "        error = delta**2\n",
    "        total_error += error\n",
    "\n",
    "        weight_delta = input[row]*delta\n",
    "        weight -= alpha*weight_delta\n",
    "    \n",
    "    #print('Weight: {} Error: {}'.format(weight,total_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "layer 0 → input \n",
    "\n",
    "layer 1 → hidden\n",
    "\n",
    "layer 2 → output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array([\n",
    "    [ 1, 0, 1 ], \n",
    "    [ 0, 1, 1 ],\n",
    "    [ 0, 0, 1 ], \n",
    "    [ 1, 1, 1 ]\n",
    "])\n",
    "\n",
    "walk_vs_stop = np.array([ 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu (x):\n",
    "    return(x>0)*x\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return (x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0_1 = 2*np.random.random([3,hidden_size]) - 1\n",
    "weights_1_2 = 2*np.random.random([hidden_size,1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Annotate what every part is doing \n",
    "\n",
    "from ast import Pass\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    layer_2_error = 0\n",
    "    for row in range(len(streetlights)):\n",
    "\n",
    "        layer_0 = streetlights[row]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        layer_2_error += (layer_2 - walk_vs_stop[row])**2\n",
    "        \n",
    "        layer_2_delta = layer_2 - walk_vs_stop[row]\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu_deriv(layer_1)\n",
    "\n",
    "        weights_1_2 -= alpha*np.outer(layer_2_delta,layer_1).T\n",
    "        weights_0_1 -= alpha*np.outer(layer_0,layer_1_delta)\n",
    "\n",
    "    if (i%10==9):\n",
    "        continue\n",
    "        #print('Error: {}'.format(layer_2_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "alpha = 0.05\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array([\n",
    "    [ 1, 0, 1 ], \n",
    "    [ 0, 1, 1 ],\n",
    "    [ 0, 0, 1 ], \n",
    "    [ 1, 1, 1 ]\n",
    "])\n",
    "\n",
    "walk_vs_stop = np.array([ 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu (x):\n",
    "    return(x>0)*x\n",
    "\n",
    "def relu_derive(x):\n",
    "    return(x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.random() -> returns random number between interval [0.0,1.0)\n",
    "#2*[0.0,1.0) - 1 -> (-1,1)\n",
    "\n",
    "weights_0_1 = 2*np.random.random([3,4]) - 1\n",
    "weights_1_2 = 2*np.random.random([4,1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    error = 0\n",
    "    for i in range(len(streetlights)):\n",
    "        #Feed-Foward part of Deep Neural Network\n",
    "        layer_0 = streetlights[i] #Dim (3,1)\n",
    "        layer_1 = relu(np.dot(layer_0.T,weights_0_1)) #Dim (_,3) x (3,4) -> (_,4)\n",
    "        layer_2 = np.dot(layer_1,weights_1_2) #Dim (_,4) x (4,1) -> (_,1)\n",
    "\n",
    "        error += (layer_2 - walk_vs_stop[i])**2 #Total Error \n",
    "        \n",
    "        layer_2_delta = (layer_2 - walk_vs_stop[i]) #Dim (_,1)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu_derive(layer_1) #Dim (_,1).(1,4)x(_,4) -> (_,4)\n",
    "        \n",
    "        weights_1_2 -= alpha*np.outer(layer_1,layer_2_delta) #Dim (_,4) o (_,1) -> (4,1)\n",
    "        weights_0_1 -= alpha*np.outer(layer_0,layer_1_delta) #Dim (3,1) o (_,4) -> (3,4)\n",
    "\n",
    "    if (epoch%10==9):\n",
    "        continue\n",
    "        #print('Error: {}'.format(error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three-layer network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:0 Error:0.722 Correct:0.537 Test-Err:0.601 Test-Acc:0.6488\n",
      " I:10 Error:0.312 Correct:0.901 Test-Err:0.420 Test-Acc:0.8114\n",
      " I:20 Error:0.260 Correct:0.937 Test-Err:0.414 Test-Acc:0.8111\n",
      " I:30 Error:0.232 Correct:0.946 Test-Err:0.417 Test-Acc:0.8066\n",
      " I:40 Error:0.215 Correct:0.956 Test-Err:0.426 Test-Acc:0.8019\n",
      " I:50 Error:0.204 Correct:0.966 Test-Err:0.437 Test-Acc:0.7982\n",
      " I:60 Error:0.194 Correct:0.967 Test-Err:0.448 Test-Acc:0.7921\n",
      " I:70 Error:0.186 Correct:0.975 Test-Err:0.458 Test-Acc:0.7864\n",
      " I:80 Error:0.179 Correct:0.979 Test-Err:0.466 Test-Acc:0.7817\n",
      " I:90 Error:0.172 Correct:0.981 Test-Err:0.474 Test-Acc:0.7758\n",
      " I:100 Error:0.166 Correct:0.984 Test-Err:0.482 Test-Acc:0.7706\n",
      " I:110 Error:0.161 Correct:0.984 Test-Err:0.489 Test-Acc:0.7686\n",
      " I:120 Error:0.157 Correct:0.986 Test-Err:0.496 Test-Acc:0.766\n",
      " I:130 Error:0.153 Correct:0.999 Test-Err:0.502 Test-Acc:0.7622\n",
      " I:140 Error:0.149 Correct:0.991 Test-Err:0.508 Test-Acc:0.758\n",
      " I:150 Error:0.145 Correct:0.991 Test-Err:0.513 Test-Acc:0.7558\n",
      " I:160 Error:0.141 Correct:0.992 Test-Err:0.518 Test-Acc:0.7553\n",
      " I:170 Error:0.138 Correct:0.992 Test-Err:0.524 Test-Acc:0.751\n",
      " I:180 Error:0.135 Correct:0.995 Test-Err:0.528 Test-Acc:0.7505\n",
      " I:190 Error:0.132 Correct:0.995 Test-Err:0.533 Test-Acc:0.7482\n",
      " I:200 Error:0.130 Correct:0.998 Test-Err:0.538 Test-Acc:0.7464\n",
      " I:210 Error:0.127 Correct:0.998 Test-Err:0.544 Test-Acc:0.7446\n",
      " I:220 Error:0.125 Correct:0.998 Test-Err:0.552 Test-Acc:0.7416\n",
      " I:230 Error:0.123 Correct:0.998 Test-Err:0.560 Test-Acc:0.7372\n",
      " I:240 Error:0.121 Correct:0.998 Test-Err:0.569 Test-Acc:0.7344\n",
      " I:250 Error:0.120 Correct:0.999 Test-Err:0.577 Test-Acc:0.7316\n",
      " I:260 Error:0.118 Correct:0.999 Test-Err:0.585 Test-Acc:0.729\n",
      " I:270 Error:0.117 Correct:0.999 Test-Err:0.593 Test-Acc:0.7259\n",
      " I:280 Error:0.115 Correct:0.999 Test-Err:0.600 Test-Acc:0.723\n",
      " I:290 Error:0.114 Correct:0.999 Test-Err:0.607 Test-Acc:0.7196\n",
      " I:300 Error:0.113 Correct:0.999 Test-Err:0.614 Test-Acc:0.7183\n",
      " I:310 Error:0.112 Correct:0.999 Test-Err:0.622 Test-Acc:0.7165\n",
      " I:320 Error:0.111 Correct:0.999 Test-Err:0.629 Test-Acc:0.7133\n",
      " I:330 Error:0.110 Correct:0.999 Test-Err:0.637 Test-Acc:0.7125\n",
      " I:340 Error:0.109 Correct:1.099 Test-Err:0.645 Test-Acc:0.71\n",
      " I:349 Error:0.108 Correct:1.0 Test-Err:0.653 Test-Acc:0.7073\n"
     ]
    }
   ],
   "source": [
    "import sys, numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "#Loading and Splitting Dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "\n",
    "for i,l in enumerate(labels): \n",
    "        one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28)/255 \n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test): \n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "relu = lambda x:(x>=0) * x\n",
    "relu2deriv = lambda x: x>=0\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10) \n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1)) \n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2) \n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1])) \n",
    "        \n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta) \n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "    \n",
    "    sys.stdout.write(\"\\r\"+ \" I:\"+str(j)+ \" Error:\" + str(error/float(len(images)))[0:5] + \" Correct:\" + str(correct_cnt/float(len(images))))\n",
    "\n",
    "    if(j % 10 == 0 or j == iterations-1): \n",
    "        error, correct_cnt = (0.0, 0)\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1)) \n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "            error += np.sum((test_labels[i:i+1] - layer_2) ** 2) \n",
    "            correct_cnt += int(np.argmax(layer_2) == \\\n",
    "            np.argmax(test_labels[i:i+1])) \n",
    "        \n",
    "        sys.stdout.write(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] + \" Test-Acc:\" + str(correct_cnt/float(len(test_images))))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err:0.653 Test-Acc:0.7073\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py3-TF2.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d3ded15803fbf556d1ea302757f6bdf1583184dfabd86dc2a6465beaf9a5135"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
