{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot and Cold Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 0.5\n",
    "goal_pred = 0.8\n",
    "weight = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_h_c(input,weight):\n",
    "    return input*weight\n",
    "\n",
    "def error_se(pred,goal_pred):\n",
    "    return (pred - goal_pred)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_h_c(input,weight)\n",
    "error = error_se(pred,goal_pred)\n",
    "\n",
    "for i in range(1101):\n",
    "    weight_delta = 0.001\n",
    "    weight_more = weight + weight_delta\n",
    "    weight_less = weight - weight_delta\n",
    "    \n",
    "    error_h = error_se(pred_h_c(input,weight_more),goal_pred)\n",
    "    error_c = error_se(pred_h_c(input,weight_less),goal_pred)\n",
    "\n",
    "    if (error_h <= error_c):\n",
    "        weight = weight_more\n",
    "    else:\n",
    "        weight = weight_less\n",
    "    \n",
    "    #print('Error: {}  Predicition: {}'.format(error_se(pred_h_c(input,weight),goal_pred),pred_h_c(input,weight)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 2\n",
    "goal_pred = 0.8\n",
    "weight = 0.5\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred_h_c(input,weight)\n",
    "error = error_se(pred,input)\n",
    "\n",
    "for i in range (50):\n",
    "    raw_error = pred - goal_pred\n",
    "    delta = (raw_error)*input ## accounts for Direction and Amount, Pure Error, Scaling Negative Reversal and Stopping\n",
    "    weight -= delta*alpha\n",
    "    pred = pred_h_c(input,weight)\n",
    "    error = error_se(pred,goal_pred)\n",
    "    #print('Error: {}  Predicition: {}'.format(error_se(pred_h_c(input,weight),goal_pred),pred_h_c(input,weight)))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "toes = [8.5, 9.5, 9.9, 9.0] \n",
    "wlrec = [0.65, 0.8, 0.8, 0.9] \n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "#Target\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_grad_desc (input, weight):\n",
    "    return np.dot(input,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(input) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with Multiple Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = np.array([toes[0],wlrec[0],nfans[0]])\n",
    "weight = np.array([0.1, 0.2, -.1])\n",
    "alpha = 0.01\n",
    "\n",
    "output = win_or_lose_binary[1]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    pred = pred_grad_desc(input,weight)\n",
    "    delta = pred - output\n",
    "    error = delta**2\n",
    "\n",
    "    weight_delta = delta\n",
    "    weight = weight - weight_delta*alpha\n",
    "\n",
    "    #print('Error: {}  Predicition: {}'.format(error,pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with Multiple Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlrec = [0.65, 1.0, 1.0, 0.9] #win percentage for games\n",
    "\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win = [1,1,0,1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "weight = np.array([0.3, 0.2, 0.9])\n",
    "alpha = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_ele_mult(number,vector):\n",
    "    output = [0,0,0]\n",
    "    assert(len(number)==len(vector))\n",
    "    for i in range(len(number)):\n",
    "        output[i] = number[i]*vector[i]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_ele_mult_num(number,vector):\n",
    "    output = [0,0,0]\n",
    "    assert(len(output)==len(vector))\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = number*vector[i]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = wlrec[0]\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "for epoch in range(100):\n",
    "    pred = weight*input\n",
    "\n",
    "    delta = [0,0,0]\n",
    "    error = [0,0,0]\n",
    "\n",
    "    for i in range(len(true)):\n",
    "        delta[i] = pred[i] - true[i]\n",
    "        error[i] = (delta[i])**2\n",
    "        \n",
    "    weight_delta = scalar_ele_mult_num(input,delta)\n",
    "    \n",
    "    weight -= scalar_ele_mult_num(alpha,weight_delta)\n",
    "    #print(\"Weights:\" + str(weight))\n",
    "    #print(\"Error:\" + str(error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with Multiple Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    [0.1, 0.1, -0.3],\n",
    "    [0.1, 0.2, 0.0],\n",
    "    [0.0, 1.3, 0.1]\n",
    " ]\n",
    "\n",
    "## Inputs\n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0] \n",
    "lrec = [0.65,0.8, 0.8, 0.9] \n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "## Outputs\n",
    "\n",
    "hurt = [0.1, 0.0, 0.0, 0.1] \n",
    "win =[1,1,0,1] \n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_mat_mult(vector, matrix):\n",
    "    output = [0,0,0]\n",
    "    assert(len(vector)==len(matrix))\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = np.dot(vector,matrix[i])\n",
    "    return output\n",
    "\n",
    "def outer_prod(vec_a,vec_b):\n",
    "    assert(len(vec_a)==len(vec_b))\n",
    "    output = np.zeros([3,3])\n",
    "    for i in range(len(vec_a)):\n",
    "        for j in range(len(vec_b)):\n",
    "            output[i,j] = vec_a[i]*vec_b[j]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [toes[0], lrec[0],nfans[0]]\n",
    "true = [hurt[0],win[0],sad[0]]\n",
    "alpha = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    pred = vec_mat_mult(input,weights)\n",
    "    delta = [0,0,0]\n",
    "    error = [0,0,0]\n",
    "    for i in range(output):\n",
    "        delta[i] = pred[i] - true[i]\n",
    "        error[i] =delta[i]**2\n",
    "    \n",
    "    weight_delta = outer_prod(input,delta)\n",
    "    \n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights)):\n",
    "            weights[i][j] -= alpha*weight_delta[i][j]\n",
    "\n",
    "    #print(\"Weights:\" + str(weight))\n",
    "    #print(\"Error:\" + str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0.5,0.48,-0.7]) \n",
    "alpha = 0.1\n",
    "\n",
    "streetlights = np.array([\n",
    "    [ 1, 0, 1 ], \n",
    "    [ 0, 1, 1 ],\n",
    "    [ 0, 0, 1 ], \n",
    "    [ 1, 1, 1 ], \n",
    "    [ 0, 1, 1 ],\n",
    "    [ 1, 0, 1 ]\n",
    "])\n",
    "\n",
    "walk_vs_stop = np.array([ 0, 1, 0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = streetlights\n",
    "output = walk_vs_stop\n",
    "\n",
    "weight = weights\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    total_error = 0\n",
    "    for row in range(len(input)):\n",
    "        pred = np.dot(input[row],weight)\n",
    "        delta = pred - output[row]\n",
    "        error = delta**2\n",
    "        total_error += error\n",
    "\n",
    "        weight_delta = input[row]*delta\n",
    "        weight -= alpha*weight_delta\n",
    "    \n",
    "    #print('Weight: {} Error: {}'.format(weight,total_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "layer 0 → input \n",
    "\n",
    "layer 1 → hidden\n",
    "\n",
    "layer 2 → output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array([\n",
    "    [ 1, 0, 1 ], \n",
    "    [ 0, 1, 1 ],\n",
    "    [ 0, 0, 1 ], \n",
    "    [ 1, 1, 1 ]\n",
    "])\n",
    "\n",
    "walk_vs_stop = np.array([ 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu (x):\n",
    "    return(x>0)*x\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return (x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0_1 = 2*np.random.random([3,hidden_size]) - 1\n",
    "weights_1_2 = 2*np.random.random([hidden_size,1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Annotate what every part is doing \n",
    "\n",
    "from ast import Pass\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    layer_2_error = 0\n",
    "    for row in range(len(streetlights)):\n",
    "\n",
    "        layer_0 = streetlights[row]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        layer_2_error += (layer_2 - walk_vs_stop[row])**2\n",
    "        \n",
    "        layer_2_delta = layer_2 - walk_vs_stop[row]\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu_deriv(layer_1)\n",
    "\n",
    "        weights_1_2 -= alpha*np.outer(layer_2_delta,layer_1).T\n",
    "        weights_0_1 -= alpha*np.outer(layer_0,layer_1_delta)\n",
    "\n",
    "    if (i%10==9):\n",
    "        continue\n",
    "        #print('Error: {}'.format(layer_2_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "alpha = 0.05\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array([\n",
    "    [ 1, 0, 1 ], \n",
    "    [ 0, 1, 1 ],\n",
    "    [ 0, 0, 1 ], \n",
    "    [ 1, 1, 1 ]\n",
    "])\n",
    "\n",
    "walk_vs_stop = np.array([ 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu (x):\n",
    "    return(x>0)*x\n",
    "\n",
    "def relu_derive(x):\n",
    "    return(x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.random() -> returns random number between interval [0.0,1.0)\n",
    "#2*[0.0,1.0) - 1 -> (-1,1)\n",
    "\n",
    "weights_0_1 = 2*np.random.random([3,4]) - 1\n",
    "weights_1_2 = 2*np.random.random([4,1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    error = 0\n",
    "    for i in range(len(streetlights)):\n",
    "        #Feed-Foward part of Deep Neural Network\n",
    "        layer_0 = streetlights[i] #Dim (3,1)\n",
    "        layer_1 = relu(np.dot(layer_0.T,weights_0_1)) #Dim (_,3) x (3,4) -> (_,4)\n",
    "        layer_2 = np.dot(layer_1,weights_1_2) #Dim (_,4) x (4,1) -> (_,1)\n",
    "\n",
    "        error += (layer_2 - walk_vs_stop[i])**2 #Total Error \n",
    "        \n",
    "        layer_2_delta = (layer_2 - walk_vs_stop[i]) #Dim (_,1)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu_derive(layer_1) #Dim (_,1).(1,4)x(_,4) -> (_,4)\n",
    "        \n",
    "        weights_1_2 -= alpha*np.outer(layer_1,layer_2_delta) #Dim (_,4) o (_,1) -> (4,1)\n",
    "        weights_0_1 -= alpha*np.outer(layer_0,layer_1_delta) #Dim (3,1) o (_,4) -> (3,4)\n",
    "\n",
    "    if (epoch%10==9):\n",
    "        continue\n",
    "        #print('Error: {}'.format(error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three-layer network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "import sys, numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Loading and Splitting Dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#Loading and Splitting Dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) 255, y_train[0:1000])\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,l in enumerate(labels): one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255 test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test): test_labels[i][l] = 1\n",
    "np.random.seed(1)\n",
    "relu = lambda x:(x>=0) * x\n",
    "relu2deriv = lambda x: x>=0\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = \\\n",
    "(0.005, 350, 40, 784, 10) weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "for j in range(iterations): error, correct_cnt = (0.0, 0)\n",
    "for i in range(len(images)):\n",
    "layer_0 = images[i:i+1]\n",
    "layer_1 = relu(np.dot(layer_0,weights_0_1)) layer_2 = np.dot(layer_1,weights_1_2)\n",
    "error += np.sum((labels[i:i+1] - layer_2) ** 2) correct_cnt += int(np.argmax(layer_2) == \\\n",
    "np.argmax(labels[i:i+1])) layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "layer_1_delta = layer_2_delta.dot(weights_1_2.T)\\ * relu2deriv(layer_1)\n",
    "weights_1_2 += alpha * layer_1.T.dot(layer_2_delta) weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "sys.stdout.write(\"\\r\"+ \\\n",
    "\" I:\"+str(j)+ \\\n",
    "\" Error:\" + str(error/float(len(images)))[0:5] +\\ \" Correct:\" + str(correct_cnt/float(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py3-TF2.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d3ded15803fbf556d1ea302757f6bdf1583184dfabd86dc2a6465beaf9a5135"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
