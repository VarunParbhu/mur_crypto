{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9554, 0.3878, 0.6026],\n",
      "        [0.6195, 0.3071, 0.5131],\n",
      "        [0.3164, 0.5277, 0.9531],\n",
      "        [0.9958, 0.6708, 0.7469],\n",
      "        [0.9618, 0.7101, 0.9266]])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2798, 0.0563, 0.5010],\n",
      "        [0.5818, 0.9039, 0.4326],\n",
      "        [0.4236, 0.2874, 0.5723],\n",
      "        [0.9219, 0.0556, 0.4720],\n",
      "        [0.4608, 0.3497, 0.2384]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998704195022583}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "print(pipeline('sentiment-analysis')('we love you'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9988259673118591}]\n"
     ]
    }
   ],
   "source": [
    "print(pipeline('sentiment-analysis')('we hate you'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1672.028, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 02:06:19.244338: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.3\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.0018993656, 'roberta_neu': 0.013890146, 'roberta_pos': 0.9842106}\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer('very good movie!', return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "}\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_daily = os.listdir('Datasets/Daily Tweet Data')\n",
    "file_path_daily.sort()\n",
    "data_path_daily = ['Datasets/Daily Tweet Data/{}'.format(file) for file in file_path_daily]\n",
    "data_path_daily = pd.DataFrame(data_path_daily,columns=['File Path'])\n",
    "data_path_daily['File Name'] = file_path_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 5308/20371 [08:51<25:08,  9.99it/s]\n",
      "1it [08:51, 531.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Datasets/Daily Tweet Data/2022-11-21 16:56:08.972373.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20204/20204 [37:31<00:00,  8.97it/s]\n",
      "100%|██████████| 20368/20368 [38:07<00:00,  8.91it/s]\n",
      " 65%|██████▍   | 13315/20563 [22:50<12:25,  9.72it/s]\n",
      "4it [1:47:22, 1681.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Datasets/Daily Tweet Data/2022-11-21 16:56:08.994254.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20744/20744 [43:46<00:00,  7.90it/s]\n",
      "100%|██████████| 20156/20156 [41:14<00:00,  8.14it/s]\n",
      "100%|██████████| 20535/20535 [47:53<00:00,  7.15it/s]\n",
      " 19%|█▊        | 3812/20602 [10:03<44:16,  6.32it/s]\n",
      "8it [4:10:24, 1831.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Datasets/Daily Tweet Data/2022-11-21 16:56:09.038100.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20306/20306 [49:34<00:00,  6.83it/s]\n",
      "100%|██████████| 20125/20125 [48:56<00:00,  6.85it/s]\n",
      " 22%|██▏       | 4600/20490 [09:38<33:17,  7.95it/s]\n",
      "11it [5:58:36, 1856.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Datasets/Daily Tweet Data/2022-11-21 16:56:09.069538.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20497/20497 [36:37<00:00,  9.33it/s]\n",
      "100%|██████████| 20452/20452 [37:03<00:00,  9.20it/s]\n",
      " 11%|█▏        | 2359/20588 [03:52<29:56, 10.15it/s]\n",
      "14it [7:16:12, 1494.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Datasets/Daily Tweet Data/2022-11-21 16:56:09.108685.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20356/20356 [39:33<00:00,  8.58it/s]\n",
      "100%|██████████| 20595/20595 [41:56<00:00,  8.18it/s]\n",
      "100%|██████████| 20556/20556 [41:42<00:00,  8.22it/s]\n",
      "100%|██████████| 20648/20648 [43:17<00:00,  7.95it/s]\n",
      "100%|██████████| 20663/20663 [44:27<00:00,  7.75it/s]\n",
      " 49%|████▊     | 9922/20452 [20:09<21:24,  8.20it/s]\n",
      "20it [11:07:24, 2040.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Datasets/Daily Tweet Data/2022-11-21 16:56:09.173208.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20173/20173 [41:08<00:00,  8.17it/s]\n",
      "100%|██████████| 20187/20187 [47:37<00:00,  7.06it/s]\n",
      "100%|██████████| 20411/20411 [35:54<00:00,  9.47it/s]\n",
      " 33%|███▎      | 6755/20572 [13:46<28:10,  8.17it/s]\n",
      "24it [13:25:55, 1865.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Datasets/Daily Tweet Data/2022-11-21 16:56:09.210500.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 94/20270 [00:26<1:36:27,  3.49it/s]\n",
      "25it [13:26:23, 1313.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "Datasets/Daily Tweet Data/2022-11-21 16:56:09.220672.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for i,file in tqdm(enumerate(data_path_daily['File Path'])):\n",
    "    try:\n",
    "        data = pd.read_csv(file,engine='python',index_col=0)\n",
    "        data['sent_score']= data['clean_tweet'].astype('str').progress_apply(polarity_scores_roberta)\n",
    "        data.to_csv('{}'.format(data_path_daily['File Path'][i]))\n",
    "    except:\n",
    "        print(i)\n",
    "        print(data_path_daily['File Path'][i])\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch_tf_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3525862eb7474a29db09ce01a834f42964e4c1bfc31ad17c337acfcc423c297f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
