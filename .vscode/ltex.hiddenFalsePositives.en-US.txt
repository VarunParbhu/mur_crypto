{"rule":"THE_SUPERLATIVE","sentence":"^\\QReplacing \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q where \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the identity matrix; we get the method of steepest descent Deep Learning.\\E$"}
{"rule":"THE_SUPERLATIVE","sentence":"^\\QReplacing \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q where \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the identity matrix; we get the method of steepest descent given by Deep Learning.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QHence, the update rule of the weights for gradient descent method is given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Learning Rate .\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Then, the mathematical definition of the MCP neuron is given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q if \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q otherwise \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Rosenblatt's Perceptron\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QPerceptron Learning Ruelee.\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_RULE","sentence":"^\\QPerceptron Convergence Theorem Theorem Consider algorithm (\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q) and let \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q be a set of training vectors which are linearly separable.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QA generic form of an optimization problem is given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Qminimize/maximize \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q subject to \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q where \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the objective/loss function to be minimised, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q are called inequality constraints, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q are called equality constraints, and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QAsur and Huberman (2010) (ADD REF) attempted to solve the revenue prediction problem using both the tweet volume and the tweet sentiment.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QSame kind of data along with polling results were also used, in Bermingham and Smeaton (2011) (ADD REF), to train a linear regression model to predict election results.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QBar-Haim et al. (2011) (ADD REF) on one hand leverage sentiments on Twitter but on the other did not treat all Twitter authors equally.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Substituting (eq: z_j partials) and (eq: partial_act_weight) into (eq: partial_C_with_weight) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q The four main back-propagation equations are given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q We vectorize the above set of equations by using the Hadamard product.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QIt is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time.\\E$"}
{"rule":"SO_AS_TO","sentence":"^\\QThe procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector.\\E$"}
{"rule":"Y_ALL","sentence":"^\\QSee y’all tomorrow.”\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QThe three types of frequency based embedding are: Count Vector, TF-IDF (Term Frequency-Inverse Term Frequency) Vector and Co-Occurence Matrix with a fixed context window.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QDeveloped by Mikolov et al in 2013 (ADD 2 REF), the word2vec was introduced.\\E$"}
{"rule":"ET_AL","sentence":"^\\QDeveloped by Mikolov et al in 2013 (ADD 2 REF), the word2vec was introduced.\\E$"}
{"rule":"NO_SPACE_CLOSING_QUOTE","sentence":"^\\QTokenizing the result above results in the list: “[”The”, “price”, “of”, “Bitcoin”, “was”, “n't”, “great”, “today”, “!”, “See”, “y’\", “all', “tomorrow”, “.”]”\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QBidirectional RNN(BRNN).\\E$"}
{"rule":"A_INFINITIVE","sentence":"^\\QThe memory cell comprises three main “gates” namely and an input node: the forget gate, the input gate, the output gate and the input node respectively.\\E$"}
{"rule":"A_INFINITIVE","sentence":"^\\QThe forget gate controls whether we keep the input from the previous hidden state or not.\\E$"}
{"rule":"A_INFINITIVE","sentence":"^\\QConsider the input \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the hidden state of the previous time step be \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the input gate be given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the forget gate given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the input node given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the output gate be \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and the memory cell state be given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q then the computations at the gates are given by:\\E$"}
{"rule":"A_INFINITIVE","sentence":"^\\QConsider the input \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the hidden state of the previous time step be \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the input gate be given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the forget gate given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the input node given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the output gate be \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and the memory cell state be given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q then the computations at the gates are given by: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Qwhere\\E$"}
{"rule":"A_INFINITIVE","sentence":"^\\QThe obtain layers is then computed to get the prediction.\\E$"}
{"rule":"A_INFINITIVE","sentence":"^\\QConsider the input \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the hidden state of the previous time step be \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the input gate be given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the forget gate given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the input node given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the output gate be \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and the memory cell state be given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q then the computations of the LSTM are given by: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Qwhere \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q are weight parameters and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q are the bias parameters.\\E$"}
{"rule":"EN_UNPAIRED_BRACKETS","sentence":"^\\QTokenizing the result above results in the list: “[”The”, “price”, “of”, “Bitcoin”, “was”, “n't”, “great”, “today”, “!”, “See”, “y’\", “all', “tomorrow”, “.”]”\\E$"}
{"rule":"A_INFINITIVE","sentence":"^\\QConsider the input \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the hidden state of the previous time step be \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the input gate be given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the forget gate given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the input node given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, the output gate be \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and the memory cell state be given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q then the computations of the LSTM are given by: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q where \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q are weight parameters and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q are the bias parameters.\\E$"}
{"rule":"EN_UNPAIRED_BRACKETS","sentence":"^\\QTokenizing the result above results in the list: “[”The”, “price”, “of”, “Bitcoin”, “was”, “n't”, “great”, “today”, “!”,\" In sentiment analysis, the tokenized sentence would be compared to predefined list polarized words (positive and negative).\\E$"}
{"rule":"NO_SPACE_CLOSING_QUOTE","sentence":"^\\QTokenizing the result above results in the list: “[”The”, “price”, “of”, “Bitcoin”, “was”, “n't”, “great”, “today”, “!”,\" In sentiment analysis, the tokenized sentence would be compared to predefined list polarized words (positive and negative).\\E$"}
{"rule":"NO_SPACE_CLOSING_QUOTE","sentence":"^\\QTokenizing the result above results in the list: [”The”, “price”, “of”, “Bitcoin”, “was”, “n't”, “great”, “today”, “!”,\" \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q\"“See”, “y’\", “all', “tomorrow”, “.”]\\E$"}
{"rule":"NO_SPACE_CLOSING_QUOTE","sentence":"^\\QTokenizing the result above results in the list: [”The”, “price”, “of”, “Bitcoin”, “was”, “n't”, “great”, “today”, “!”,\" \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q“See”, “y’\", “all', “tomorrow”, “.”]\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QThen, we perform feature engineering by cleaning the data, generating sentiment scores of Tweets using the state-of-art model roBERTa, identifying any potential influencers using K-Means neighbouring, performing hourly aggregations and finally scaling the data.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QDue to its volatility and never seen behaviour like traditional currencies, Bitcoin (and cryptocurrencies in general) are extremely difficult to predict.\\E$"}
{"rule":"EN_UNPAIRED_BRACKETS","sentence":"^\\QBitcoin was the first cryptocurrency to be operational in January 2009 after the appearance of the mysterious paper titled \"Bitcoin: A Peer-to-Peer Electronic Cash System”, published in 2008 under the alias “Satoshi Nakamoto” (a person or group of people) (ADD REF).\\E$"}
{"rule":"EN_UNPAIRED_BRACKETS","sentence":"^\\QBitcoin was the first cryptocurrency to be operational in January 2009 after the appearance of the mysterious paper titled \"Bitcoin: A Peer-to-Peer Electronic Cash System”, published in 2008 under the alias “Satoshi Nakamoto” (a person or group of people) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qvar = 1 + 1 var Google Trends.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qprint('Hello World!')\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qmystyle backgroundcolor=, commentstyle=, keywordstyle=, numberstyle=, stringstyle=, basicstyle=, breakatwhitespace=false, breaklines=true, captionpos=b, keepspaces=true, numbers=left, numbersep=5pt, showspaces=false, showstringspaces=false, showtabs=false, tabsize=2\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Qmystyle backgroundcolor=, commentstyle=, keywordstyle=, numberstyle=, stringstyle=, basicstyle=, breakatwhitespace=false, breaklines=true, captionpos=b, keepspaces=true, numbers=left, numbersep=5pt, showspaces=false, showstringspaces=false, showtabs=false, tabsize=2\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Qstyle=mystyle\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_BEGINNING_RULE","sentence":"^\\QGoogle trend data is a reflection of the volume of searches that people do.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QApplying the python function defined in listing \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q to the raw tweet in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q leads to the following string: ' mushroom the psychonaut ape division mushroom too weird to live and too rare to die framed picture a bold collection of psychonaut apes by internationally recognised artist woahjonny nft nfts ethereum eth eth crypto solana bnb avax tezos tron bitcoin btc' We apply the pre-process tweet function across the 814,818 tweets that were scraped.\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_RULE","sentence":"^\\QApplying the python function defined in listing \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q to the raw tweet in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q leads to the following string: ' mushroom the psychonaut ape division mushroom too weird to live and too rare to die framed picture a bold collection of psychonaut apes by internationally recognised artist woahjonny nft nfts ethereum eth eth crypto solana bnb avax tezos tron bitcoin btc' We apply the pre-process tweet function across the 814,818 tweets that were scraped.\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_RULE","sentence":"^\\QApplying the python function defined in listing \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q to the raw tweet in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q leads to the following string: 'mushroom the psychonaut ape division mushroom too weird to live and too \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q rare to die framed picture a bold collection of psychonaut apes by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q internationally recognised artist woahjonny nft nfts ethereum eth eth crypto \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q solana bnb avax tezos tron bitcoin btc' We apply the pre-process tweet function across the 814,818 tweets that were scraped.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWe used the version cardiffnlp/twitter-roberta-base-sentiment published by Hugging Face Hourly Averaging.\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_RULE","sentence":"^\\QApplying the python function defined in listing \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q to the raw tweet in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q leads to the following string: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q 'mushroom the psychonaut ape division mushroom too weird to live and too \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q rare to die framed picture a bold collection of psychonaut apes by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q internationally recognised artist woahjonny nft nfts ethereum eth eth crypto \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q solana bnb avax tezos tron bitcoin btc' We apply the pre-process tweet function across the 814,818 tweets that were scraped.\\E$"}
