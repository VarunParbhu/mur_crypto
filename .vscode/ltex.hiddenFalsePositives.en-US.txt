{"rule":"THE_SUPERLATIVE","sentence":"^\\QReplacing \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q where \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the identity matrix; we get the method of steepest descent Deep Learning.\\E$"}
{"rule":"THE_SUPERLATIVE","sentence":"^\\QReplacing \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q where \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the identity matrix; we get the method of steepest descent given by Deep Learning.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QHence, the update rule of the weights for gradient descent method is given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Learning Rate .\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Then, the mathematical definition of the MCP neuron is given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q if \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q otherwise \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Rosenblatt's Perceptron\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QPerceptron Learning Ruelee.\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_RULE","sentence":"^\\QPerceptron Convergence Theorem Theorem Consider algorithm (\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q) and let \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q be a set of training vectors which are linearly separable.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QA generic form of an optimization problem is given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Qminimize/maximize \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q subject to \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q where \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the objective/loss function to be minimised, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q are called inequality constraints, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q are called equality constraints, and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QAsur and Huberman (2010) (ADD REF) attempted to solve the revenue prediction problem using both the tweet volume and the tweet sentiment.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QSame kind of data along with polling results were also used, in Bermingham and Smeaton (2011) (ADD REF), to train a linear regression model to predict election results.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QBar-Haim et al. (2011) (ADD REF) on one hand leverage sentiments on Twitter but on the other did not treat all Twitter authors equally.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Substituting (eq: z_j partials) and (eq: partial_act_weight) into (eq: partial_C_with_weight) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q The four main back-propagation equations are given by \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q We vectorize the above set of equations by using the Hadamard product.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QIt is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time.\\E$"}
{"rule":"SO_AS_TO","sentence":"^\\QThe procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector.\\E$"}
{"rule":"Y_ALL","sentence":"^\\QSee y’all tomorrow.”\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QThe three types of frequency based embedding are: Count Vector, TF-IDF (Term Frequency-Inverse Term Frequency) Vector and Co-Occurence Matrix with a fixed context window.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QDeveloped by Mikolov et al in 2013 (ADD 2 REF), the word2vec was introduced.\\E$"}
{"rule":"ET_AL","sentence":"^\\QDeveloped by Mikolov et al in 2013 (ADD 2 REF), the word2vec was introduced.\\E$"}
{"rule":"NO_SPACE_CLOSING_QUOTE","sentence":"^\\QTokenizing the result above results in the list: “[”The”, “price”, “of”, “Bitcoin”, “was”, “n't”, “great”, “today”, “!”, “See”, “y’\", “all', “tomorrow”, “.”]”\\E$"}
