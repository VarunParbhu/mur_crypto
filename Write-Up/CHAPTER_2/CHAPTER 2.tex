\chapter{Deep Learning Networks}
\section{Introduction}
Deep learning is a multidisciplinary field ranging from linear algebra, calculus and probability theory. With major advancement made in compute processing power; deep learning is commonly used in the industry now.
\vspace{5mm}
\\
\noindent\textbf{McCullough and Walter Pitts (MCP) Neuron}\\
In 1943, McCulloch and Walter Pitts demonstrated that simple binary threshold units wired up as logical gates could be used to build a digital computer (add-ref). The McCulloch-Pitts (MCP) neuron is a simple mathematical model of a biological neuron. It was the earliest mathematical model of a neural network and had only three types of weights; excitatory (1), inhibitory (-1) and inactive (0). The model had an activation function which had a value of 1 if the weighted sum was greater or equal to a given threshold, else 0. Using the MCP neuron, one of the first digital computers that contained stored programs was built. However, the MCP neuron was very restrictive.
\vspace{5mm}
\\
\noindent\textbf{Rosenblattâ€™s Perceptron Algorithm}\\
In 1958, Frank Rosenblatt proposed the perceptron and an algorithm to adjust weights of the MCP neuron, extending the work done by McCulloch and Pitts. The MCP neuron had some limitations that the Perceptron managed to solve, for example the input was not restricted to boolean values but expanded to real numbers. Rosenblatt proved that if the data used to train the perceptron are linearly separable classes, then the perceptron algorithm convergences and separates the two classes by a hyperplane.
\vspace{5mm}
\\
\noindent\textbf{Perceptron}\\
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_perceptron_2.jpeg}
  \caption{Rosenblatt perceptron}
  \label{rosenblatt_perceptron}
\end{figure}
\vspace{5mm}
\\
\noindent Let $\textbf{x}$ be a vector of inputs where each $x_i \in \mathbb{Z}$ and $\textbf{w}$ be a vector of weights corresponding to the input signals where each $w_i \in \mathbb{Z}$. 
\begin{align}
  \begin{matrix}
    \textbf{x} = \begin{bmatrix}
      x_{0} \\
      x_{1} \\
      \vdots \\
      x_{n}
    \end{bmatrix}, & \textbf{w} = \begin{bmatrix}
      w_{0} \\
      w_{1} \\
      \vdots \\
      w_{n}
    \end{bmatrix}
  \end{matrix} \nonumber
\end{align}
\noindent Then, the mathematical definition of the perceptron is given by
\begin{align}
  \phi(z) = \begin{cases}
    1 & \text{if } \sum^{n}_{i=0} w_ix_i \geq  0\\
    0 & \text{otherwise}
    \label{eq:mcp_neuron}
  \end{cases}
\end{align}
\vspace{5mm}
\\
where $\phi(z)$ is known as the hard delimiter.
\vspace{5mm}
\\
\noindent Consider the two sets of point \textbf{A} and \textbf{B} 
\begin{align}
  \textbf{A} =
  \begin{Bmatrix}
    \begin{bmatrix}
      1 \\ 
      2
    \end{bmatrix}
  \end{Bmatrix}
   \, \, \, 
  \textbf{B} =
\begin{Bmatrix}
  \begin{bmatrix}
    -1 \\
    2
  \end{bmatrix},
  \begin{bmatrix}
    0 \\
    -1
  \end{bmatrix}
  \end{Bmatrix}
\end{align}
and fitting the perceptron function (\refeq{eq:mcp_neuron}) to learn how to classify points in each respective set. Let set \textbf{A} and \textbf{B} be class 1 and 0 respectively.
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_perceptron_example_1.jpeg}
  \caption{Caption}
  \label{fig:perceptron_example_1}
\end{figure}\\
From \ref{fig:perceptron_example_1}, we can separate the two classes by a single line. Consider the random separating line passing through the origin (this will set the value of $x_0$ in (\refeq{eq:mcp_neuron}) to 0).\\
\begin{figure}[!htbp]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_perceptron_example_2.jpeg}
  \caption{Caption}
  \label{fig:perceptron_example_2}
\end{figure}\\
The equation of the random line is given by
\begin{align}
  x_1 = - x_2
\end{align}
Comparing to the equation (\refeq{eq:mcp_neuron}); we can deduce that 
\begin{align}
  \begin{matrix}
    w_1 = 1 & w_2 = 1
  \end{matrix}
\end{align}
Visually, we can already see that the separating line does not split the points properly. The computation of the binary classification using the random line is given by
\begin{align}
  \phi(A_1) &= \phi\begin{pmatrix}
    \begin{bmatrix}
      1\\
      1
    \end{bmatrix}.\begin{bmatrix}
      1 \\
      2
    \end{bmatrix}
  \end{pmatrix} = \phi(3) = 1 \\
  \phi(B_1) &= f\begin{pmatrix}
    \begin{bmatrix}
      1\\
      1
    \end{bmatrix}.\begin{bmatrix}
      -1 \\
      2
    \end{bmatrix}
  \end{pmatrix} = \phi(1) = 1 \\
  \phi(B_2) &= f\begin{pmatrix}
    \begin{bmatrix}
      1\\
      1
    \end{bmatrix}.\begin{bmatrix}
      -1 \\
      0
    \end{bmatrix}
  \end{pmatrix} = \phi(-1) = 0
\end{align}
The computation confirms the visual representation and groups $\textbf{A}_1$ and $\textbf{B}_1$ together and $\textbf{B}_2$ separated which is incorrect. We can either alter the separating line (by moving the weight vector) with respect to $\textbf{A}_1$ and/or $\textbf{B}_1$.
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.25]{CHAPTER_2/c2_fig_perceptron_example_3.jpeg}
  \caption{!!!TO BE CHANGED!!!}
  \label{fig:perceptron_example_3}
\end{figure}\\
Since $\textbf{B}_1$ is incorrectly classified, using the property of subtraction of vectors; we move the weight vector ($\textbf{w}$) away from $\textbf{B}_1$ and check the classification again.
\begin{align}
  \textbf{w}^{(1)} &= \textbf{w} - \textbf{B}_1 \\
  &= \begin{bmatrix}
    1 \\
    1
  \end{bmatrix} - \begin{bmatrix}
    -1 \\
    2
  \end{bmatrix} \\
  & = \begin{bmatrix}
    2 \\
    -1
  \end{bmatrix}
\end{align}\\
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_perceptron_example_4.jpeg}
  \caption{!!!!TO BE CHANGED!!!!}
  \label{fig:perceptron_example_4}
\end{figure} \\
Based on the new separating line, we can observe visually that the points are correctly classified. The computation of the binary classification using the new separating line $\textbf{w}^{(1)}$ is given by
\begin{align}
  \phi(A_1) &= \phi\begin{pmatrix}
    \begin{bmatrix}
      2\\
      -1
    \end{bmatrix}.\begin{bmatrix}
      1 \\
      2
    \end{bmatrix}
  \end{pmatrix} = \phi(0) = 1 \\
  \phi(B_1) &= \phi\begin{pmatrix}
    \begin{bmatrix}
      2\\
      -1
    \end{bmatrix}.\begin{bmatrix}
      -1 \\
      2
    \end{bmatrix}
  \end{pmatrix} = \phi(-4) = 0 \\
  \phi(B_2) &= \phi\begin{pmatrix}
    \begin{bmatrix}
      2\\
      -1
    \end{bmatrix}.\begin{bmatrix}
      -1 \\
      0
    \end{bmatrix}
  \end{pmatrix} = \phi(-2) = 0
\end{align}
Thus, the perceptron learned how to classify the two sets of points. The function $f(\textbf{x})$ could be re-used to classify new points added to the sets.
\vspace{5mm}
\\
\noindent\textbf{Perceptron Algorithm}\\
The perceptron algorithm adjusts the weights and as a result, the hard delimiter as well in order to linearly separate a set of binary labelled input.

\begin{algorithm}
\caption{Perceptron Algorithm}\label{alg:perceptron_algorithm}
\begin{algorithmic}[1]
\Require \\
Let $t=0$ and $\textbf{w} = \begin{bmatrix}
  0 & 0 & \dots & 0
\end{bmatrix}^T$ \\
Consider the training set D $s.t$ $D = C_1 \cup C_2$  \\
$C_1$ $\leftarrow$ input with label 1 \\
$C_2$ $\leftarrow$ input with label 0\\
\textbf{Start}
\While{!convergence}
  \State Select a random input $\textbf{x}$
  \If{$\textbf{x}\in A$ and $\textbf{w}.\textbf{x}<0$}
  \State $\textbf{w} = \textbf{w} + \textbf{x}$
  \EndIf
  \If{$\textbf{x}\in B$ and $\textbf{w}.\textbf{x}\geq0$}
  \State $\textbf{w} = \textbf{w} - \textbf{x}$
  \EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}
\noindent If the input data are binary and linearly separable; then algorithm (\ref{alg:perceptron_algorithm}) converges. The proof of convergence of the algorithm is known as the \textbf{perceptron convergence theorem}. \vspace{5mm} \\
\noindent\textbf{Perceptron Convergence Theorem }\vspace{5mm}\\
\textbf{Theorem}\\
Consider algorithm (\ref{alg:perceptron_algorithm}) and let $D$ be a set of training vectors which are linearly separable. Let $\textbf{w}^{*}$ be the weight vectors which defines the separating line with $||\textbf{w}^{*}|| = 1$. Then the number of mistakes $m$ made by the perceptron algorithm satisfies 
\begin{align}
  \begin{matrix}
    m \leq \dfrac{1}{\gamma^2} & \text{where} & \gamma = \underset{\textbf{x}\in D}{\min} \dfrac{|{\textbf{w}^*}^T\textbf{x}|}{||\textbf{x}||_2}
  \end{matrix}
\end{align}
\textbf{Note}
\begin{enumerate}
  \item Since, $||\textbf{w}^{*}|| = 1 \implies \cos (\theta) = \dfrac{{\textbf{w}^*}^T\textbf{x}}{||\textbf{x}||_2}$
  \item If $||\textbf{x}||_2 = 1$, that is, we scale all the training examples to have unit norm (which has no effect their orientation), then $\gamma = \underset{\textbf{x}\in D}{\min} |{\textbf{w}^*}^T\textbf{x}|$ is the minimum distance from any example $\textbf{x} \in D$ to the separating line.
\end{enumerate}
\textbf{Proof}\\
We first prove the inequality given by 
\begin{align}
  (\textbf{w}^ {(t+1)})^T\textbf{w}^{*} \geq (\textbf{w}^ {(t)})^T\textbf{w}^{*} + \gamma
  \label{eq:per_cov_ine_1}
\end{align}
\indent \textbf{State 1} \\
In state 1, let us consider \textbf{x} being positive ($\textbf{x} \in C_1$) and incorrectly classified then
\begin{align}
  \nonumber
  (\textbf{w}^ {(t+1)})^T\textbf{w}^{*} = (\textbf{w}^ {(t)} + \textbf{x})^T\textbf{w}^{*} =   (\textbf{w}^ {(t)})^T\textbf{w}^{*} + \textbf{x}^T\textbf{w}^{*}
\end{align}
Assuming that all $||\textbf{x}||_2 = 1$ then $\textbf{x}^T\textbf{w}^{*} \geq \gamma$ since $\gamma$ is the minimum. 
\begin{align}
  \label{eq:per_cov_ine_2}
  (\textbf{w}^ {(t+1)})^T\textbf{w}^{*} \geq (\textbf{w}^ {(t)})^T\textbf{w}^{*} + \gamma
\end{align}
Thus, we have proved (\ref{eq:per_cov_ine_1})  under \textbf{State 1}.\\
\indent \textbf{State 2} \\
In state 2, let us consider \textbf{x} being negative ($\textbf{x} \in C_2$) and incorrectly classified then
\begin{align}
  \nonumber
  (\textbf{w}^ {(t+1)})^T\textbf{w}^{*} = (\textbf{w}^ {(t)} - \textbf{x})^T\textbf{w}^{*} =   (\textbf{w}^ {(t)})^T\textbf{w}^{*} - \textbf{x}^T\textbf{w}^{*}
\end{align}
Since $\textbf{x} \in C_2 \implies |{\textbf{w}^*}^T\textbf{x}| = - \textbf{x}^T\textbf{w}^* \geq 0$ and $|\textbf{x}^T\textbf{w}^{*}| \geq \gamma$
\begin{align}
  \nonumber
  (\textbf{w}^ {(t+1)})^T\textbf{w}^{*} &= (\textbf{w}^ {(t)})^T\textbf{w}^{*} + |{\textbf{w}^*}^T\textbf{x}| \\
  \label{eq:per_cov_ine_3}
  (\textbf{w}^ {(t+1)})^T\textbf{w}^{*} &\geq (\textbf{w}^ {(t)})^T\textbf{w}^{*} + \gamma
\end{align}
Thus, we have proved (\ref{eq:per_cov_ine_1})  under \textbf{State 2}.\\
From (\ref{eq:per_cov_ine_2}) and (\ref{eq:per_cov_ine_3}), we have shown that $\forall \textbf{x}\in D$ that inequality (\ref{eq:per_cov_ine_1}) holds.\\
Assume that the inequality (\ref{eq:per_cov_ine_1}) holds for an arbitrary integer value $m$ and $m-1$
\begin{align}
  \label{eq:induction_1}
  (\textbf{w}^ {(m)})^T\textbf{w}^{*} \geq (\textbf{w}^ {(m-1)})^T\textbf{w}^{*} + \gamma \\
  \label{eq:induction_2}
  (\textbf{w}^ {(m-1)})^T\textbf{w}^{*} \geq (\textbf{w}^ {(m-2)})^T\textbf{w}^{*} + \gamma 
\end{align}
Merging inequality (\ref{eq:induction_1}) and (\ref{eq:induction_2}) gives us
\begin{align}
  \label{eq:induction_3}
  (\textbf{w}^ {(m)})^T\textbf{w}^{*} \geq (\textbf{w}^ {(m-2)})^T\textbf{w}^{*} + 2\gamma
\end{align}
Hence, by induction, after $M$ mistakes, inequality (\ref{eq:induction_3}) becomes
\begin{align}
  \label{eq:induction_starts}
  (\textbf{w}^ {(m)})^T\textbf{w}^{*} \geq (\textbf{w}^ {(0)})^T\textbf{w}^{*} + m\gamma
\end{align}
Since $\textbf{w}^{(0)} = \mathbf{0}$ (the zero vector), we have
\begin{align}
  \label{eq:perp_cov_result1}
  (\textbf{w}^ {(m)})^T\textbf{w}^{*} \geq m\gamma
\end{align}
Next, we show that 
\begin{align}
  ||{\textbf{w}^{(t+1)}}||_{2}^{2} \leq ||{\textbf{w}^{(t)}}||_{2}^{2} + 1
  \label{eq:induction_proof_part2}
\end{align}
\indent \textbf{State 1} \\
Consider the same state 1 as before, thus we have
\begin{align}
  \begin{matrix}
    \label{eq:state1_conditions}
    (\textbf{w}^ {(t)})^T\textbf{x} \leq 0 & \text{and} & \textbf{w}^ {(t+1)} = \textbf{w}^{(t)} + \textbf{x}
  \end{matrix}
\end{align}
then
\begin{align}
  \nonumber
  ||\textbf{w}^{(t+1)}||_{2}^{2} &= ( \textbf{w}^{(t)} + \textbf{x})^T( \textbf{w}^{(t)} + \textbf{x}) \\
  \nonumber
  &=( \textbf{w}^{(t)} + \textbf{x})^T\textbf{w}^{(t)} + ( \textbf{w}^{(t)} + \textbf{x})^T\textbf{x} \\
  \nonumber
  &= (\textbf{w}^{(t)})^T\textbf{w}^{(t)} + \textbf{x}^T\textbf{w}^{(t)} + (\textbf{w}^{(t)})^T\textbf{x} + \textbf{x}^T\textbf{x}\\
  &= (\textbf{w}^{(t)})^T\textbf{w}^{(t)} + 2 (\textbf{w}^{(t)})^T\textbf{x}  + \textbf{x}^T\textbf{x}
  \label{eq:state_1_proof}
\end{align}
Since (\ref{eq:state1_conditions}) and $\textbf{x}^T\textbf{x} = 1$, equation (\ref{eq:state_1_proof}) becomes
\begin{align}
  ||{\textbf{w}^{(t+1)}}||_{2}^{2} \leq ||{\textbf{w}^{(t)}}||_{2}^{2} + 1
\end{align}
\indent \textbf{State 2} \\
Consider the same state 2 as before, thus we have
\begin{align}
  \begin{matrix}
    \label{eq:state2_conditions}
    (\textbf{w}^ {(t)})^T\textbf{x} > 0 & \text{and} & \textbf{w}^ {(t+1)} = \textbf{w}^{(t)} - \textbf{x}
  \end{matrix}
\end{align}
then
\begin{align}
  \nonumber
  ||\textbf{w}^{(t+1)}||_{2}^{2} &= ( \textbf{w}^{(t)} - \textbf{x})^T( \textbf{w}^{(t)} - \textbf{x}) \\
  \nonumber
  &=( \textbf{w}^{(t)} - \textbf{x})^T\textbf{w}^{(t)} - ( \textbf{w}^{(t)} - \textbf{x})^T\textbf{x} \\
  \nonumber
  &= (\textbf{w}^{(t)})^T\textbf{w}^{(t)} - \textbf{x}^T\textbf{w}^{(t)} - (\textbf{w}^{(t)})^T\textbf{x} + \textbf{x}^T\textbf{x}\\
  &= (\textbf{w}^{(t)})^T\textbf{w}^{(t)} - 2 (\textbf{w}^{(t)})^T\textbf{x}  + \textbf{x}^T\textbf{x}
  \label{eq:state_2_proof}
\end{align}
Since (\ref{eq:state2_conditions}) and $\textbf{x}^T\textbf{x} = 1$, equation (\ref{eq:state_2_proof}) becomes
\begin{align}
  ||{\textbf{w}^{(t+1)}}||_{2}^{2} \leq ||{\textbf{w}^{(t)}}||_{2}^{2} + 1
\end{align}
Thus, we have proved (\ref{eq:induction_proof_part2}) under \textbf{State 2}.\\
By the same induction defined in (\ref{eq:induction_starts}), we have
\begin{align}
  \label{eq:perp_cov_result2}
  ||\textbf{w}^{(m)}||_{2}^{2} \leq m
\end{align}
Finally, we merge result (\ref{eq:perp_cov_result1}) and (\ref{eq:perp_cov_result2}) using the Cauchy-Schwarz (CS) inequality \\
Recall that the CS inequality is given by
\begin{align}
  \label{eq:CS_inquality}
  |{\textbf{w}^*}^T\textbf{x}| \leq ||\textbf{w}^{*}||_2 ||\textbf{x}||_2
\end{align}
Hence, using (\ref{eq:CS_inquality}) we get
\begin{align}
  \label{eq:after_cs}
  |(\textbf{w}^{m})^T\textbf{w}^{*}| \leq ||(\textbf{w}^{m})^T||_2  ||\textbf{w}^{*}||_2
\end{align}
From the result (\ref{eq:perp_cov_result1}), (\ref{eq:after_cs}) becomes
\begin{align}
  m\gamma \leq |(\textbf{w}^{m})^T\textbf{w}^{*}| \leq ||(\textbf{w}^{m})^T||_2  ||\textbf{w}^{*}||_2
\end{align}
Using the result (\ref{eq:perp_cov_result2}) and the fact that $||\textbf{w}^{*}||_{2} = 1$, we get
\begin{align}
  \nonumber
  m\gamma &\leq ||(\textbf{w}^{m})^T||_2 \\
  m^2 {\gamma}^2 &\leq ||(\textbf{w}^{m})^T||_{2}^{2} \\
  m^2 {\gamma}^2 &\leq m \\
  m &\leq \dfrac{1}{\gamma^2}
\end{align}
This proves the Perceptron Convergence Theorem that the number of mistakes is at most $\dfrac{1}{\gamma^2}$, where $\gamma$ is the margin.\vspace{5mm}\\
\noindent\textbf{Solving Gate problem using the Perceptron}\\
The perceptron alone is not always a good model to solve binary classification problem. It has certain limitation by nature of its definition. Consider the logic functions AND, OR and XOR across these 4 points:
\begin{align}
  \begin{matrix}
    \textbf{p}_1 = \begin{bmatrix}
      0 \\
      0
    \end{bmatrix},
    \textbf{p}_2 = \begin{bmatrix}
      1 \\
      0
    \end{bmatrix},
    \textbf{p}_3 = \begin{bmatrix}
      1 \\
      1
    \end{bmatrix},
    \textbf{p}_4 = \begin{bmatrix}
      0 \\
      1
    \end{bmatrix}  
  \end{matrix}
\end{align}
\subsubsection*{AND Function}
The AND function returns a value of 1 if both of the inputs is 1. Let $f$ be the AND function such that
\begin{align}
\begin{matrix}
  \nonumber
  f(\textbf{p}_1) = 0 & f(\textbf{p}_2) = 0 & f(\textbf{p}_3) = 1 & f(\textbf{p}_4) = 0
\end{matrix}  
\end{align}
Consider the AND function with the separating line below
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_AND_function.jpeg}
  \caption{AND Function with separating line}
  \label{AND_function_2}
\end{figure}\vspace{50mm}\\
The equation of the separating line in figure \ref{AND_function_2} is given by
\begin{align}
  x_1 + x_2 -1.5 = 0
\end{align}
We can transform the separating line in the form of $\textbf{w}^T\textbf{x} = 0$ to fit the perceptron.\\
Let 
\begin{align}
  \begin{matrix}
    \textbf{w} = \begin{bmatrix}
      -1.5 \\
      1 \\
      1
    \end{bmatrix} & \text{and} & \textbf{x} = \begin{bmatrix}
      1 \\
      x_1 \\
      x_2
    \end{bmatrix}
  \end{matrix}
\end{align}
Applying function (\ref{eq:mcp_neuron}) on each point to check whether they are correctly classified.
\begin{align}
  \nonumber
  \begin{matrix}
    \phi(p_1) = \phi\begin{pmatrix}
      \begin{bmatrix}
        -1.5 \\
        1 \\
        1 
      \end{bmatrix}.\begin{bmatrix}
        1 \\
        0 \\
        0
      \end{bmatrix}
    \end{pmatrix} = \phi(-1.5) = 0 
  \end{matrix}
\end{align}
\begin{align}
  \nonumber
  \begin{matrix}
    \phi(p_2) = \phi\begin{pmatrix}
      \begin{bmatrix}
        -1.5 \\
        1 \\
        1 
      \end{bmatrix}.\begin{bmatrix}
        1 \\
        1 \\
        0
      \end{bmatrix}
    \end{pmatrix} = \phi(-0.5) = 0
  \end{matrix}
\end{align}
\begin{align}
  \nonumber
  \begin{matrix}
    \phi(p_3) = \phi\begin{pmatrix}
      \begin{bmatrix}
        -1.5 \\
        1 \\
        1 
      \end{bmatrix}.\begin{bmatrix}
        1 \\
        1 \\
        1
      \end{bmatrix}
    \end{pmatrix} = \phi(0.5) = 1
  \end{matrix}
\end{align}
\begin{align}
  \nonumber
  \begin{matrix}
    \phi(p_4) = \phi\begin{pmatrix}
      \begin{bmatrix}
        -1.5 \\
        1 \\
        1 
      \end{bmatrix}.\begin{bmatrix}
        1 \\
        0 \\
        1
      \end{bmatrix}
    \end{pmatrix} = \phi(-0.5) = 0
  \end{matrix}
\end{align}
Thus, the perceptron is able to solve the AND function.
\subsubsection*{OR Function}
The OR function returns a value of 1 if either of the inputs is 1. Let $f$ be the OR function such that
\begin{align}
\begin{matrix}
  \nonumber
  f(\textbf{p}_1) = 0 & f(\textbf{p}_2) = 1 & f(\textbf{p}_3) = 1 & f(\textbf{p}_4) = 1
\end{matrix}  
\end{align}
Consider the OR function with the separating line below
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_OR_function.jpeg}
  \caption{AND Function with separating line}
  \label{OR_function}
\end{figure}\vspace{50mm}\\
The equation of the separating line in figure \ref{OR_function} is given by
\begin{align}
  x_1 + x_2 - 0.5 = 0
\end{align}
We can transform the separating line in the form of $\textbf{w}^T\textbf{x} = 0$ to fit the perceptron.\\
Let 
\begin{align}
  \begin{matrix}
    \textbf{w} = \begin{bmatrix}
      -0.5 \\
      1 \\
      1
    \end{bmatrix} & \text{and} & \textbf{x} = \begin{bmatrix}
      1 \\
      x_1 \\
      x_2
    \end{bmatrix}
  \end{matrix}
\end{align}
Applying function (\ref{eq:mcp_neuron}) on each point to check whether they are correctly classified.
\begin{align}
  \nonumber
  \begin{matrix}
    \phi(p_1) = \phi\begin{pmatrix}
      \begin{bmatrix}
        -0.5 \\
        1 \\
        1 
      \end{bmatrix}.\begin{bmatrix}
        1 \\
        0 \\
        0
      \end{bmatrix}
    \end{pmatrix} = \phi(-0.5) = 0 
  \end{matrix}
\end{align}
\begin{align}
  \nonumber
  \begin{matrix}
    \phi(p_2) = \phi\begin{pmatrix}
      \begin{bmatrix}
        -0.5 \\
        1 \\
        1 
      \end{bmatrix}.\begin{bmatrix}
        1 \\
        1 \\
        0
      \end{bmatrix}
    \end{pmatrix} = \phi(0.5) = 1
  \end{matrix}
\end{align}
\begin{align}
  \nonumber
  \begin{matrix}
    \phi(p_3) = \phi\begin{pmatrix}
      \begin{bmatrix}
        -0.5 \\
        1 \\
        1 
      \end{bmatrix}.\begin{bmatrix}
        1 \\
        1 \\
        1
      \end{bmatrix}
    \end{pmatrix} = \phi(1.5) = 1
  \end{matrix}
\end{align}
\begin{align}
  \nonumber
  \begin{matrix}
    \phi(p_4) = \phi\begin{pmatrix}
      \begin{bmatrix}
        -0.5 \\
        1 \\
        1 
      \end{bmatrix}.\begin{bmatrix}
        1 \\
        0 \\
        1
      \end{bmatrix}
    \end{pmatrix} = \phi(0.5) = 1
  \end{matrix}
\end{align}
Thus, the perceptron is able to solve the OR function.
\subsubsection*{XOR Function}
The XOR function returns a value of 1 if either of the inputs is 1 but not both. Let $f$ be the XOR function such that
\begin{align}
  \begin{matrix}
    f(\textbf{p}_1)=0,&   f(\textbf{p}_2)=1 ,& f(\textbf{p}_3)=0,&   f(\textbf{p}_4)=1    
  \end{matrix}
\end{align}
Consider a plot of the XOR function below 
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_rig_XOR.jpeg}
  \caption{OR function}
  \label{XOR_function}
\end{figure}\\
From figure \ref{XOR_function}; we can observe that no separating line alone could group the two different classes together. We attempt to find a combination of weight for the perceptron which reduces the error (margin) as much as possible.\\

\noindent Let $f^{*}$ be the exact function and $f(\textbf{x},\textbf{w}) = \textbf{w}^T\textbf{x} + b$, where $\textbf{w} = [w_1 \, \, w_2]^T$, be the approximate function. Consider the error function (the difference between the exact and approximate value)
\begin{align}
  \label{eq:error_XOR_prob}
  \mathbb{E}(\textbf{w},b) = \dfrac{1}{4} \sum_{x\in D}(f^{*}(\textbf{x})- \textbf{w}^T\textbf{x}-b)^2
\end{align}
we minimise the error function $\mathbb{E}$ by setting the partial derivatives to 0. The partial derivative with respect to the bias is given by
\begin{align}
  \nonumber
  \dfrac{\partial \mathbb{E}}{\partial b} &= -\dfrac{1}{2} \sum_{x\in D}(f^{*}(\textbf{x})- \textbf{w}^T\textbf{x}-b)\\
  \label{eq:bias_derivative}
  \dfrac{\partial \mathbb{E}}{\partial b} = 0\rightarrow \sum_{x\in D}f^{*}(\textbf{x}) &= \sum_{x\in D}\textbf{w}^T\textbf{x}- \sum_{x\in D}b
\end{align}
The partial derivative with respect to the weight vector is given by
\begin{align}
  \nonumber
  \dfrac{\partial \mathbb{E}}{\partial \textbf{x}} &= \dfrac{1}{2} \sum_{x\in D}(f^{*}(\textbf{x})- \textbf{w}^T\textbf{x}-b) \dfrac{\partial (-\textbf{w}^T\textbf{x})}{\partial \textbf{w}}\\
  \nonumber
  &=-\dfrac{1}{2} \sum_{x\in D}(f^{*}(\textbf{x})- \textbf{w}^T\textbf{x}-b)\textbf{x}\\
  \label{eq:weight_derivative}
  \dfrac{\partial \mathbb{E}}{\partial \textbf{w}} = 0\rightarrow \sum_{x\in D}\textbf{x}f^{*}(\textbf{x}) &= \sum_{x\in D}(\textbf{w}^T\textbf{x})\textbf{x} + b\sum_{x\in D}\textbf{x}
\end{align}
Substituting for values in equation (\ref{eq:bias_derivative})
\begin{align}
  \sum_{x\in D}f^{*}(\textbf{x}) &= f^{*}(\textbf{p}_1) + f^{*}(\textbf{p}_2) + f^{*}(\textbf{p}_3) + f^{*}(\textbf{p}_4) \nonumber \\
  &= 0+1+1+0 \nonumber \\
  & = 2 \\
  \sum_{x\in D}\textbf{w}^T\textbf{x} &= \textbf{w}^T\begin{bmatrix}
    0 \\
    0
  \end{bmatrix} + \textbf{w}^T\begin{bmatrix}
    1 \\
    0
  \end{bmatrix} + \textbf{w}^T\begin{bmatrix}
    1 \\
    1
  \end{bmatrix}+ \textbf{w}^T\begin{bmatrix}
    0 \\
    1
  \end{bmatrix} \nonumber \\
  &= 2w_1 + 2w_2 \\
  \nonumber
  \sum_{x\in D}b &= b \sum_{x\in D} 1 \\&= 4b
\end{align}
Thus, we get
\begin{align}
\nonumber 2 &= 2w_1 + 2w_2 + 4b \\
w_1 + w_2 + 2b &= 1
\label{eq:first_set_normal_eq}
\end{align}
Substituting for values in equation (\ref{eq:weight_derivative})
\begin{align}
  \sum_{x\in D}\textbf{x}f^{*}(\textbf{x}) &= \begin{bmatrix}
    0 \\
    0
  \end{bmatrix}(0) + \begin{bmatrix}
    1 \\
    0
  \end{bmatrix}(1) + \begin{bmatrix}
    1 \\
    1
  \end{bmatrix}(0)+ \begin{bmatrix}
    0 \\
    1
  \end{bmatrix}(1) \nonumber \\
  &= \begin{bmatrix}
    1 \\
    1
  \end{bmatrix}\\
  \nonumber
  \sum_{x\in D}(\textbf{w}^T\textbf{x})\textbf{x} &= \begin{bmatrix}
    w_1 & w_2
  \end{bmatrix} \begin{bmatrix}
    0 \\
    0
  \end{bmatrix} \begin{bmatrix}
    0 \\
    0
  \end{bmatrix} + \begin{bmatrix}
    w_1 & w_2
  \end{bmatrix} \begin{bmatrix}
    1 \\
    0
  \end{bmatrix} \begin{bmatrix}
    1 \\
    0
  \end{bmatrix} \\ \nonumber
  &+ \begin{bmatrix}
    w_1 & w_2
  \end{bmatrix} \begin{bmatrix}
    1 \\
    1
  \end{bmatrix} \begin{bmatrix}
    1 \\
    1
  \end{bmatrix} + \begin{bmatrix}
    w_1 & w_2
  \end{bmatrix} \begin{bmatrix}
    0 \\
    1
  \end{bmatrix} \begin{bmatrix}
    0 \\
    1
  \end{bmatrix} \\
  &= \begin{bmatrix}
    2w_1 + w_2 \\
    w_1 + 2w_2
  \end{bmatrix} \\
  \nonumber 
  b\sum_{x\in D}\textbf{x} &= 
    b\begin{bmatrix}
      0 \\
      0
    \end{bmatrix} + b\begin{bmatrix}
      1 \\
      0
    \end{bmatrix} + b\begin{bmatrix}
      1 \\
      1
    \end{bmatrix} + b\begin{bmatrix}
      0 \\
      1
    \end{bmatrix}\\
  &= b\begin{bmatrix}
    2 \\
    2
  \end{bmatrix}
\end{align}
Thus, we get
\begin{align}
  \label{eq:second_set_normal_eq}
\begin{bmatrix}
  1 \\
  1
\end{bmatrix}  &= \begin{bmatrix}
  2w_1 + w_2 \\
  w_1 + 2w_2
\end{bmatrix} + b\begin{bmatrix}
  2 \\
  2
\end{bmatrix}
\end{align}
From equations (\ref{eq:first_set_normal_eq}) and (\ref{eq:second_set_normal_eq}), we get the set of equations that forms the approximate function with the minimum error
\begin{align}
  w_1 + w_2 + 2b &= 1 \nonumber \\
  2w_1 + w_2 + 2b &= 1 \nonumber\\
  w_1 + 2w_2 + 2b &= 1 \nonumber
\end{align}
Solving the system of linear equations we get
\begin{align}
\begin{matrix}
  w_1 = 0 & w_2 = 0 & b = \dfrac{1}{2}
\end{matrix}  
\end{align}
Hence, the approximate function $f(\textbf{x},\textbf{w})$ is given by
\begin{align}
  f(\textbf{x},\textbf{w}) = \dfrac{1}{2}
\end{align}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_XOR_soln.jpeg}
  \caption{XOR approximate solution}
  \label{fig: approximate_XOR_solution}
\end{figure}\\
\noindent  Clearly from figure \ref{fig: approximate_XOR_solution}, the perceptron model cannot solve the XOR logic function. The XOR problem is actually not linearly separable. Thus, we introduce \textbf{feedforward networks} to overcome this problem.
\subsection{Feedforward Networks}

\section{Differential calculus}
Differential calculus is the study of the definition, properties, and applications the derivative of a function. The process of finding the derivative is called differentiation. It is the also referred to as the study of rate of change and slopes of curves. In optimization and deep learning, major concepts of differential calculus are used.
\subsection{Derivatives}
Derivatives are important concept for understanding deep learning. The derivative of a function at a particular point is the rate of change of the output of the function with respect to the input at that point. It is also an indication of the slope of the function at a particular point.\\
The mathematical definition of the derivative of a function $f = f(x)$ at a point $a$ is given by
\begin{align}
  f^{'}(a) &= \frac{df}{d x}(a) \\ 
  &= \lim_{\Delta \rightarrow 0} \frac{f(a+\Delta) - f(a-\Delta)}{2 \times \Delta}
\end{align}
\begin{center}
  *Image Placeholder derivative of a function $f$ at $a$ in $\mathbb{R}^2$  and $\mathbb{R}^3$*    
\end{center}
Since the derivative of a function is an indication of the slope of a function; we can deduce that a minimum or maximum point exists when the derivative is equal to $0$ (may also be indication of an inflection point).

\vspace{5mm}
\noindent \textbf{Derivative of Multivariate Functions}
\subsection{Directional Derivatives}
\subsection{Chain Rule}
 The chain rule is a concept in calculus to help us understand and calculate the derivative for composite functions which can be made up of two or more functions chained together. \\
Suppose that we have two function $f(x)$ and $g(x)$ which are both differentiable and define the composite function $h(x) = f(g(x))$ then the derivative of $h^{'}(x)$ is given by
\begin{align}
  h^{'}(x) &= \dfrac{dh}{dx} \\
  &= f^{'}(g(x))g^{'}(x)
\end{align}
Consider that we  have $y=f(u)$ and $u=g(x)$, a different definition of the composite function $y=f(g(x))$, then the derivative of $y$ is,
\begin{align}
  h^{'}(x)  &= \dfrac{dh}{dx} \\
  &= \dfrac{dh}{du} \dfrac{du}{dx}
\end{align}
\subsection{Hessian}
\section{Optimization}
The optimization problem is a computational problem in which the objective is to find the best of all possible solutions. Deep neural networks is a form of an optimization problem to find the best possible set of weights in order to reduce the error in a network.

\noindent A generic form of an optimization problem is given by 
\begin{align}
  \begin{matrix}
    \underset{x}{\text{minimize/maximize}} &f(x) & \\
    \text{subject to} &g_i(x) \leq 0, \, \, & i=1,\dots,m \\
    &h_j(x) = 0, & j=1,\dots,p
  \end{matrix}
  \label{eq:optimization_problem}
\end{align} 
\noindent where \\
\indent $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is the objective/loss function to be minimized,\\
\indent $g_i(x) \leq 0$ are called inequality constraints,\\
\indent $h_j(x) = 0$ are called equality constraints, and \\
\indent $m\geq0$ and $p\geq0$

\vspace{5mm}
\noindent If $m=p=0$, the problem is an unconstrained optimization problem.
\subsection{Optimization algorithms}
The solutions to the optimization problem are vital in modern machine learning and artificial intelligence algorithms, which includes weight optimization in deep learning. There are a number of popular optimization algorithm currently developed to solve the problem. Hence, choosing the right algorithm can be challenging as well.
\vspace{5mm}
\noindent We explore few of the gradient-based solution to the optimization below. Gradient-based methods are iterative methods that use the gradient information of the objective function during iterations.

\vspace{5mm}
\noindent\textbf{Newton's Method}\\
For minimizing $f(x)$, $x \in \mathbb{R}$, we need to solve $g(x) = f^{'}(x)=0$. Newton's iteration is given by 
\begin{align}
  x_{n+1} &= x_{n} - \dfrac{g(x_{}n)}{g^{'}(x_n)} \\
          &= x_{n} - \dfrac{f^{'}(x_{}n)}{f^{''}(x_n)}
\end{align}
For multivariate functions we need to minimize $f(\mathbf{x})$ over $\mathbf{x} \in \mathbb{R}^n$, that it
\begin{align}
  \begin{matrix}
    \underset{\mathbf{x}\in\mathbb{R}^n}{min} f(\mathbf{x}), & \,\,\, \mathbf{x} =(x_1,x_2,\dots,x_n)^T \in \mathbb{R}^n
  \end{matrix} 
\end{align}
The Newton's iteration for multivariate function is given by
\begin{align}
  \mathbf{x_{n+1}} = \mathbf{x_{n}} - H(\mathbf{x_n})^{-1}\nabla f(\mathbf{x_n})
\end{align}
where\\
\indent $H(\mathbf{x_n})$ is the Hessian matrix of $f(\mathbf{x})$\\
\noindent We can observe from (equation ref) that calculating the inverse of the Hessian matrix can be computationally very expensive for higher dimensions. Replacing $H(\mathbf{x_n})^{-1}$ by $\alpha \mathcal{I}$ where $\mathcal{I}$ is the identity matrix; we get the \textbf{method of steepest descent} given by
\begin{align}
  \mathbf{x_{n+1}} = \mathbf{x_{n}} - \alpha \textbf{I} \nabla f(\mathbf{x_n})
\end{align}
where $\alpha \in (0,1)$ 
\section{Deep Learning}
%\noindent - Short dive into deep learning and its advancement in recent years
%\noindent - Explanation of OR and XOR functions
Deep learning is part of Machine Learning which deals mainly with computers that can learn either on their own or supervised. The latter can solve problem in the industry ranging from computer vision (image), natural language processing (text), automatic speech recognition (audio), time-series prediction amongst others. Deep learning primarily uses the concept of artificial neural networks, which derivatives from how the human brain works, to solve complex linear and non-linear problem.\\
\indent We start by introducing how a simple perceptron works, and gradually increase the complexity of the network until we reach a deep neural network that can solve non-linear problems.
\subsection{Perceptron}
%- Explanation on neuron and short numeric exercise \\ 
%- Solving the XOR OR function using Perceptron
A perceptron is an analogy to the human neuron. It is a computational model that takes an input (scalar or vector) and learns to classify the latter between two classes (binary classifier). It consists of an input, a weighed sum and an activation function. \\ The mathematical definition a perceptron that maps its input $\textbf{x}$ to an output value $f(\textbf{x})$ using a step function as activation function is given by
\begin{align}
  f(\textbf{x}) =
  \begin{cases}
    1 & \text{if } \textbf{w.x} + b > 0 \\
    0 & \text{otherwise}
    \label{eq:perceptron_def}
  \end{cases}
\end{align}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_perceptron.jpeg}
  \caption{Perceptron graphical representation}
  \label{fig:perceptron}
\end{figure}\\
From the perceptron mathematical definition \refeq{eq:perceptron_def}, we can observe that the dot product is dependent on the angle between the weight vector (\textbf{w}) and the input vector (\textbf{x}). Using dot product (\refeq{eq:cosine_rule_dot_product}), addition (\refeq{eq:addition_vectors}) and subtraction (\refeq{eq:subtraction_vectors}) of vector property; we can define a learning rule for modifying the perceptron to learn how to classify a set of input.
\subsection{Perceptron Learning Ruelee}
\noindent Consider the two sets of point \textbf{A} and \textbf{B} 
\begin{align}
  \textbf{A} =
  \begin{Bmatrix}
    \begin{bmatrix}
      1 \\ 
      2
    \end{bmatrix}
  \end{Bmatrix}
   \, \, \, 
  \textbf{B} =
\begin{Bmatrix}
  \begin{bmatrix}
    -1 \\
    2
  \end{bmatrix},
  \begin{bmatrix}
    0 \\
    -1
  \end{bmatrix}
  \end{Bmatrix}
\end{align}
and fitting the perceptron function (\refeq{eq:perceptron_def}) to learn how to classify points in each respective set. Let set \textbf{A} and \textbf{B} be class 1 and 0 respectively.
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_perceptron_example_1.jpeg}
  \caption{Caption}
  \label{fig:perceptron_example_11}
\end{figure}\\
From \ref{fig:perceptron_example_1}, we can separate the two classes by a single line. Consider the random separating line passing through the origin (this will set the value of b in (\refeq{eq:perceptron_def}) to 0).\\
\begin{figure}[!htbp]
  \centering \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_perceptron_example_2.jpeg}
  \caption{Caption}
  \label{fig:perceptron_example_22}
\end{figure}\\
The equation of the random line is given by
\begin{align}
  x_1 = - x_2
\end{align}
Comparing to the equation (\refeq{eq:perceptron_def}); we can deduce that 
\begin{align}
  \begin{matrix}
    w_1 = 1 & w_2 = 1
  \end{matrix}
\end{align}
Visually, we can already see that the separating line does not split the points properly. The computation of the binary classification using the random line is given by
\begin{align}
  f(A_1) &= f\begin{pmatrix}
    \begin{bmatrix}
      1\\
      1
    \end{bmatrix}.\begin{bmatrix}
      1 \\
      2
    \end{bmatrix}
  \end{pmatrix} = f(3) = 1 \\
  f(B_1) &= f\begin{pmatrix}
    \begin{bmatrix}
      1\\
      1
    \end{bmatrix}.\begin{bmatrix}
      -1 \\
      2
    \end{bmatrix}
  \end{pmatrix} = f(1) = 1 \\
  f(B_2) &= f\begin{pmatrix}
    \begin{bmatrix}
      1\\
      1
    \end{bmatrix}.\begin{bmatrix}
      -1 \\
      0
    \end{bmatrix}
  \end{pmatrix} = f(-1) = 0
\end{align}
The computation confirms the visual representation and groups $\textbf{A}_1$ and $\textbf{B}_1$ together. We can either alter the separating line (by moving the weight vector) with respect to $\textbf{A}_1$ and/or $\textbf{B}_1$.\vspace{50mm}
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.2]{CHAPTER_2/c2_fig_perceptron_example_3.jpeg}
  \caption{Caption}
  \label{fig:perceptron_example_33}
\end{figure}\\
Using the property of subtraction of vectors; we move the weight vector ($\textbf{w}$) away from $\textbf{B}_1$ and check the classification again. We  also introduce a learning rate $\alpha$ to control how much rotation we want. Let $\alpha = 0.5$
\begin{align}
  \textbf{w}^{(1)} &= \textbf{w} - \alpha\textbf{B}_1 \\
  &= \begin{bmatrix}
    1 \\
    1
  \end{bmatrix} - 0.5\begin{bmatrix}
    -1 \\
    2
  \end{bmatrix} \\
  & = \begin{bmatrix}
    1.5 \\
    0
  \end{bmatrix}
\end{align}\\
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_perceptron_example_4.jpeg}
  \caption{Caption}
  \label{fig:perceptron_example_44}
\end{figure} \\
Based on the new separating line, we can observe visually that the points are correctly classified. The computation of the binary classification using the new separating line $\textbf{w}^{(1)}$ is given by
\begin{align}
  f(A_1) &= f\begin{pmatrix}
    \begin{bmatrix}
      1.5\\
      0
    \end{bmatrix}.\begin{bmatrix}
      1 \\
      2
    \end{bmatrix}
  \end{pmatrix} = f(1.5) = 1 \\
  f(B_1) &= f\begin{pmatrix}
    \begin{bmatrix}
      1.5\\
      0
    \end{bmatrix}.\begin{bmatrix}
      -1 \\
      2
    \end{bmatrix}
  \end{pmatrix} = f(-1) = 0 \\
  f(B_2) &= f\begin{pmatrix}
    \begin{bmatrix}
      1.5\\
      0
    \end{bmatrix}.\begin{bmatrix}
      -1 \\
      0
    \end{bmatrix}
  \end{pmatrix} = f(-1.5) = 0
\end{align}
Thus, the perceptron learned how to classify the two sets of points. The function $f(\textbf{x})$ could be re-used to classify new points added to the sets.
\subsubsection{Perceptron Update Rule}
We can define a set number of rules for the perceptron to find the optimal weight vector to classify the points. Based on the properties of the dot product; the classification of the points are dependent on the inner angle between the normal of the separating line and the vector to be classified. If the inner angle is less than $90^\circ$ then the point belongs to class 1 else to class 0.\vspace{10mm}

\noindent \textbf{Target Classes and Errors} \\
Let the target(actual) classes be $y=1$ and $y=0$. Then the network error ${\epsilon}$ is given by the difference between the true value and the predicted value.
\begin{align*}
  \text{Network Error } \, \, \, \, \, \, \, {\epsilon}(\textbf{x}) &= y - f(\textbf{x})  \\
  \text{Correct Classification } \, \, \, \, y&=1, f(\textbf{x})=1 \rightarrow {\epsilon}(\textbf{x})=0 \\
  y&=0, f(\textbf{x})=0 \rightarrow {\epsilon}(\textbf{x})=0 \\
  \text{Incorrect Classification } \, \, \, \, y&=1, f(\textbf{x})=0 \rightarrow {\epsilon}(\textbf{x})=1 \\
  y&=0, f(\textbf{x})=1 \rightarrow {\epsilon}(\textbf{x})=-1
\end{align*}
We find that updating the weight vector can be written as
\begin{align}
  \textbf{w}^{(t+1)} = \textbf{w}^{(t)} + \alpha\epsilon(\textbf{x})\textbf{x}
\end{align}
\textbf{Perceptron Learning Algorithm}\\
The steps for the perceptron to learn how to perform binary classification is given by the steps below. Let $t$ be the $t^{th}$ iteration when learning and $b$ be in an input bias.

\vspace{5mm}
\noindent Assignment $\rightarrow$ Assign $t=0$, $\textbf{w}^{(0)} = (0,0,\dots,0)$, $b^{(0)}=0$\\
Start $\rightarrow$ For $t=0,1,2,\dots$ until convergence\\
\indent Step 1 $\rightarrow$ Randomly choose a vector $\textbf{x}^{(t)}$ with the corresponding $y^{(t)}$ (known)\\
\indent Step 2 $\rightarrow$ Compute $\textbf{z}=\textbf{w}^{(t)}.\textbf{x}^{(t)} + b^{(t)}$\\
\indent Step 3 $\rightarrow$ Compute $\epsilon^{(t)}(\textbf{z}) = y^{(t)} - f(\textbf{z}) $\\
\indent Step 4 $\rightarrow$ Update weight $\textbf{w}^{(t+1)} = \textbf{w}^{(t)} + \alpha\epsilon^{(t)}(\textbf{z})\textbf{x}^{(t)}$ \\
\indent Step 5 $\rightarrow$ Update bias  $b^{(t+1)} = b^{(t)} + \alpha\epsilon^{(t)}(\textbf{z})$
\vspace{10mm}
\\
The current perceptron we have defined is for a binary classification; we can also define multiclass perceptron and/or use different types of activation functions.
\subsubsection{Limitation of the Perceptron}
The perceptron alone is not always a good model to solve binary classification problem. It has certain limitation by nature of its definition. Consider the logic functions AND, OR and XOR across these 4 points:
\begin{align}
  \begin{matrix}
    \textbf{x}_1 = \begin{bmatrix}
      0 \\
      0
    \end{bmatrix},
    \textbf{x}_2 = \begin{bmatrix}
      1 \\
      0
    \end{bmatrix},
    \textbf{x}_3 = \begin{bmatrix}
      1 \\
      1
    \end{bmatrix},
    \textbf{x}_4 = \begin{bmatrix}
      0 \\
      1
    \end{bmatrix}  
  \end{matrix}
\end{align}
\subsubsection*{AND Function}
*Placeholder*
\subsubsection*{OR Function}
The OR function returns a value of 1 if either of the inputs is 1.
\begin{align}
  \begin{matrix}
    f^{*}(\textbf{x}_1)=0,&   f^{*}(\textbf{x}_2)=1,& f^{*}(\textbf{x}_3)=1,&   f^{*}(\textbf{x}_4)=1    
  \end{matrix}
\end{align} \\
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_OR.jpeg}
  \caption{OR function}
  \label{OR_function_2}
\end{figure}
\vspace{100mm}
\noindent From figure \ref{OR_function}; we can easily define a separating line by the perceptron to separate the two classes.
\subsubsection*{XOR Function}
The XOR function returns a value of 1 if either of the inputs is 1 but not both.
\begin{align}
  \begin{matrix}
    f^{*}(\textbf{x}_1)=0,&   f^{*}(\textbf{x}_2)=1 ,& f^{*}(\textbf{x}_3)=0,&   f^{*}(\textbf{x}_4)=1    
  \end{matrix}
\end{align} 
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_rig_XOR.jpeg}
  \caption{OR function}
  \label{XOR_function_2}
\end{figure} \\
\noindent From figure \ref{XOR_function}; we can observe that no separating line alone could group the two different classes together. The perceptron model cannot solve the XOR logic function. Thus, we introduce \textbf{neural networks} to overcome this problem.
\subsection{Neural Network}
%- Combination of Neurons to form a network \refeq{fig:perceptron} - done
%- Feedfoward network - done
%- Explanation on how Network are just matrix multiplication - done
%- Explanation on error function and the generalization in Neural Network; and optimization problem - done
%- Adjusting the weight using Gradient Descent - done
%- Back propagation
A neural network is a set of perceptron connected together which takes an input, manipulate the information to learn from it and outputs a prediction. A neural network attempts to learn a mapping from an input to an output. The goal is to reduce the error between the prediction by the network compared to the true value as much as possible.
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_neural_network_1.jpeg}
  \caption{Caption}
  \label{neural_network}
\end{figure}
\vspace{10mm} \\
The neural network model can be represented by a series of matrix multiplication which takes the input and feeds the network. This is also known as a \textbf{feedforward network}.
\subsubsection{Feedforward Network}
Consider the simple network below with 2 input neurons, 2 perceptrons and 1 output.\\
\begin{figure}[!h]
  \centering
  \includegraphics[scale=0.1]{CHAPTER_2/c2_fig_neural_network_2.jpeg}
  \caption{Caption}
  \label{neural_network_2}
\end{figure}
\vspace{20mm} \\
The feedforward network takes the information at the input and forwards it to the next layer after applying the weight vector for each respective hidden layer. This operation can be expressed as a series of matrix multiplication defined next. The input vector is given by $\textbf{x}$, random weight matrices by $\textbf{W}_i$ and the actual output be ${y}$.
\begin{align}
  \begin{matrix}
    \textbf{x} = \begin{bmatrix}
      x_{11} \\
      x_{21} \\
      b
    \end{bmatrix} & \textbf{W}_1 = \begin{bmatrix}
      w_{11} & w_{12} \\
      w_{21} & w_{22} \\
      w_{31} & w_{32}
    \end{bmatrix} & \textbf{W}_2 = \begin{bmatrix}
      m_{11} \\
      m_{21} 
    \end{bmatrix} &
    \textbf{y} = \begin{bmatrix}
      y
    \end{bmatrix}  
  \end{matrix}
\end{align}
The feedforward neural network for a single input vector can then be expressed as a series matrix multiplication to estimate the actual value of \textbf{y}. Let $\widehat{{y}}$ be the estimated value of ${y}$.
\begin{align}
  \widehat{{y}} &= f\begin{pmatrix}f(\textbf{x}^T\textbf{W}_1)\textbf{W}_2 \end{pmatrix} \nonumber\\
  &=f\begin{pmatrix}
    f\begin{pmatrix}\begin{bmatrix}
      x_{11} & x_{21} & b
    \end{bmatrix} \begin{bmatrix}
      w_{11} & w_{12} \\
      w_{21} & w_{22} \\
      w_{31} & w_{32} 
    \end{bmatrix}
  \end{pmatrix}\begin{bmatrix}
    m_{11} \\
    m_{21} 
  \end{bmatrix}
\end{pmatrix}
\label{neural_net_def}  
\end{align}
where $f$ is the function (\refeq{eq:perceptron_def}).
\subsubsection*{Solution to the XOR function}
One solution to the XOR function can be obtained using the neural network (\refeq{neural_net_def}) with the set go weights given by
\begin{align}
  \begin{matrix}
    \textbf{x} = \begin{bmatrix}
      x_{11} \\
      x_{21} \\
      -\frac{1}{2}
    \end{bmatrix} & \textbf{W}_1 = \begin{bmatrix}
      1 & -1 \\
      -1 & 1 \\
      1 & 1
    \end{bmatrix} & \textbf{W}_2 = \begin{bmatrix}
      1 \\
      1
    \end{bmatrix} &
    \textbf{y} = \begin{bmatrix}
      y
    \end{bmatrix}  
  \end{matrix}
\end{align}
\textbf{Verifying the Solution}
\begin{align}
  \begin{matrix}
    \begin{bmatrix}
      x_{11} \\
      x_{12}
    \end{bmatrix} = \begin{bmatrix}
      0 \\
      0
    \end{bmatrix} \rightarrow & \widehat{y} = 0 & 
    \begin{bmatrix}
      x_{11} \\
      x_{12}
    \end{bmatrix} = \begin{bmatrix}
      1 \\
      0
    \end{bmatrix} \rightarrow & \widehat{y} = 1 \\
    \\
    \begin{bmatrix}
      x_{11} \\
      x_{12}
    \end{bmatrix} = \begin{bmatrix}
      0 \\
      1
    \end{bmatrix} \rightarrow & \widehat{y} = 1 & 
    \begin{bmatrix}
      x_{11} \\
      x_{12}
    \end{bmatrix} = \begin{bmatrix}
      1 \\
      1
    \end{bmatrix} \rightarrow & \widehat{y} = 0
  \end{matrix}
\end{align}
The neural network correctly classifies all input. While feed-forward network of this form helped us to solve the XOR function it is very limited. The architecture defined can only be used for linearly separable problem. In order to allow for non-linear solution; we need to introduce some non-linearity in the model. This is done by using different kinds of \textbf{activation functions} in the perceptrons.
\subsubsection{Activation Functions}
Activation functions can be used with a perceptron to introduce non-linearity. The function to be used is subjective to the problem being solved and the form of the desired result we want. Some activation functions are defined below.\\
\textbf{Linear}
\begin{align}
  \phi(z) = z
\end{align}
\textbf{Unit Step (Heaviside Function)}
\begin{align}
  \phi(z) = \begin{cases}
    0 & z<0 \\
    0.5 & z=0 \\
    1 & z>0
  \end{cases}
\end{align}
\textbf{Signum}
\begin{align}
  \phi(z) = \begin{cases}
    -1 & z<0 \\
    0 & z=0 \\
    1 & z>0
  \end{cases}
\end{align}
\textbf{Sigmoid}
\begin{align}
  \phi(z) = \frac{1}{1+ e^{-z}}
\end{align}
\textbf{Hyperbolic Tangent(tanh)}
\begin{align}
  \phi(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
\end{align}
\textbf{ReLU}
\begin{align}
  \phi(z) = \begin{cases}
    0 & z<0 \\
    z & z>0
  \end{cases}
\end{align}
\subsubsection{Network Error}
The network error is given by the squared difference between the predicted value and the true value. The difference is squared to avoid the sum of errors of multiple input vector to be zero which can mislead the network to have perfect predictive power.
\begin{align}
  \text{Network Error } e = \dfrac{1}{2}\sum^{\text{Total Input}}_i (\widehat{y_i}-y_i)^2
  \label{network_error}
\end{align}
The goal of the network is to adjust the weight to reduce the network error as much as possible. The idea of reducing a function to a value is synonymous to (\refeq{eq:optimization_problem}) an optimization problem. The network error in (\refeq{network_error}) is a quadratic equation.\\
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_network_error.jpeg}
  \caption{Network Error}
  \label{network_error_graph}
\end{figure}\vspace{70mm}\\
Figure (\ref*{network_error_graph}) is a graphical representation of the network error function. Our goal is to reach the minimum of the function by adjusting the weight value. We use the \textbf{gradient descent method} to reach the bottom of the curve.
\subsubsection{Gradient Descent Method}
In order to reach the bottom of the function; we need to adjust the weight such that the derivative of the error function is 0. The approach of updating the weight based on the gradient of the error function is known as \textbf{gradient descent}. The derivative with respect to the weights of the network error (\refeq{network_error}) for a single input is given by
\begin{align}
  \frac{de}{dw_{ij}} = (\widehat{y_i}-y_i)\frac{d\widehat{y_i}}{dw_{ij}}
  \label{derivative_network_error}
\end{align}
From figure (\refeq{network_error_graph}); we can observe that if the gradient is negative then we have underestimated the predicted value and need to increase the weight to reach the optimal value. On the other hand, if the gradient is positive then we have overestimated the predicted value and need to decrease the weight to reach the optimal value. The equation (\refeq{derivative_network_error}) provides us with the opposite direction and amount to adjust the weight. Hence, the update rule of the weights for gradient descent method is given by
\begin{align}
  w_{ij}^{t+1} = w_{ij}^{t} - \dfrac{de}{dw_{ij}}
\end{align}
In the gradient descent method, the network learns from the gradient of the error function and adjust the weights accordingly to reduce the error. However, the gradient alone can be quite large, causing oscillations as we go down the error function. We fix this problem by introducing a \textbf{learning rate} $\alpha$ prior to adjusting the weight.
\subsubsection{Learning Rate}
The learning rate is typically denoted by the Greek letter alpha $\alpha$. It helps the network to control the rate at which the weights are changing. Having a system with a high learning rate may lead to an oscillating network when trying to find the optimal weight and having a slow learning rate increases the number of iterations required when optimizing the network. The adjusted update rule of the weight is given by
\begin{align}
  w_{ij}^{t+1} = w_{ij}^{t} - \alpha\dfrac{de}{dw_{ij}}
\end{align}
where $\alpha \in (0,1)$
\subsubsection{Back Propagation}
The input data has been fed forward in the network. Then the error function and the gradient descent method we have defined are both executed at the end of neural network we have defined in equation (\refeq{neural_net_def}). We now need a way to back propagate the weight changes that need to happened from the output neuron to the input neuron in between each layer. This whole process is known as \textbf{back propagation}.\\
Consider the neural network below.
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.15]{CHAPTER_2/c2_fig_back_prog.jpeg}
  \caption{Back propagation}
  \label{}
\end{figure}\vspace{50mm} \\
Let the perceptron at output layer have a linear activation function while the perceptron layer have ReLU activation functions. \\
- Explain what happens at the end of the neural network
- Explain what happens in between layers
- Explain how to back propagate to the start of the network.

\subsection{Deep Neural Network}
%- Explain why Deep Neural Network multiple-layer backpropagation
%- Different types of activation function
%- Back propagation in deep neural network explanation
\subsection{Overfitting}
\subsubsection{Dropout}
\subsection{Convolutional Layer} 