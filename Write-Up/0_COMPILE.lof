\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Rosenblatt perceptron\relax }}{4}{figure.caption.7}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Set $\mathbf {A}$ and $\mathbf {B}$ with a random separating line\relax }}{5}{figure.caption.8}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Set $\mathbf {A}$ and $\mathbf {B}$ with a random separating line and its weight vector\relax }}{6}{figure.caption.9}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Set $\mathbf {A}$ and $\mathbf {B}$ after adjusting the separating line and its weight vector\relax }}{7}{figure.caption.10}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces AND Function with separating line\relax }}{13}{figure.caption.12}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces OR Function with separating line\relax }}{14}{figure.caption.14}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces XOR function\relax }}{16}{figure.caption.16}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces XOR approximate solution\relax }}{19}{figure.caption.17}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Representation of Truth Table for function $f_1^{*}$\relax }}{20}{figure.caption.19}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Representation of Truth Table for function $f_2^{*}$\relax }}{21}{figure.caption.21}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces FFN hidden layer\relax }}{23}{figure.caption.23}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Representation of the hidden layer\relax }}{24}{figure.caption.25}%
\contentsline {figure}{\numberline {2.13}{\ignorespaces Feedforward network for XOR problem\relax }}{25}{figure.caption.26}%
\contentsline {figure}{\numberline {2.14}{\ignorespaces Neural Network with $N$ number of layers\relax }}{28}{figure.caption.27}%
\contentsline {figure}{\numberline {2.15}{\ignorespaces Consecutive layers, $l$ and $l+1$, in a neural network\relax }}{29}{figure.caption.28}%
\contentsline {figure}{\numberline {2.16}{\ignorespaces An RNN with a hidden state\relax }}{35}{figure.caption.30}%
\contentsline {figure}{\numberline {2.17}{\ignorespaces Computing the hidden state in an LSTM model\relax }}{36}{figure.caption.32}%
\contentsline {figure}{\numberline {2.18}{\ignorespaces Architecture of a bidirectional RNN\relax }}{38}{figure.caption.34}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Minimum and Maximum points\relax }}{40}{figure.caption.36}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Network Error over different weight\relax }}{42}{figure.caption.38}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces !!!TO BE CHANGED!!!-Transformer Layer\relax }}{54}{figure.caption.49}%
