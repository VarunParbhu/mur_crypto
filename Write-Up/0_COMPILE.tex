\documentclass[a4paper,12pt,hidelinks]{report}
\usepackage{array}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}\usepackage[pagebackref=true]{hyperref}
\usepackage{amsmath}
\usepackage{harvard}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subfigure}
\usepackage{epsfig}
\usepackage[inner= 4cm, outer=2cm, top=3cm, bottom=3cm]{geometry}
\usepackage{setspace}
\renewcommand{\baselinestretch}{1.5}
\usepackage{amsfonts}
\usepackage{caption}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}


\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\begin{document}
\begin{titlepage}
\begin{center}
\begin{huge}
\textbf{The Effect of News Sentiment and Google Search Indices on the Performance of a Deep Learning Approach to Modelling Bitcoin Prices}\\
\end{huge}
\vspace{10mm}
\begin{huge}
by \\
PARBHU Varun \\ 
\end{huge}
\begin{large}
\vspace{15mm}
Project Supervisor: Professor (Dr) BHURUTH MUDDUN OSK \\
\vspace{15mm}
Project submitted to the Department of Mathematics,\\
Faculty of Science, University of Mauritius,\\
as a partial fulfillment of the requirement\\
for the degree of\\
\textbf{M.Sc. Mathematical and Scientific Computing (Part time)}\\
\end{large}
\vspace{30mm}
December 2022
\end{center}
\end{titlepage}
\pagenumbering{roman}
\tableofcontents


\listoffigures
\addcontentsline{toc}{section}{\listfigurename}

\listoftables
\addcontentsline{toc}{section}{\listtablename}

\chapter*{Acknowledgement}
\addcontentsline{toc}{section}{Acknowledgement}
First and foremost, I would like to show my deepest gratitude to my supervisor Professor (Dr) M. Bhuruth for his guidance and recommendations throughout the project. Also, I would like to thank my family and friends for their constant support during the coursework.

\noindent Lastly, I would like to thank my colleagues for their constant support.
\chapter*{Abstract}
\addcontentsline{toc}{section}{Abstract}
Cryptocurrencies have been gaining much attention in the past few years due to their steep increase in value. They are speculative, which fuels the necessity of understanding their behaviour over time. This dissertation studies the principle of deep learning and different sequential neural network architecture. An approach to modelling Bitcoin price over a 24hr period using an LSTM NN is proposed. The Tweepy API is used to get news about Bitcoin from Twitter. We continuously scrape, tweets and the total number of tweets hourly, containing 'bitcoin', 'BTC' or '\#btc' for 42 days. The roBERTa model is then used to get the sentiment score (positive, neutral, negative) from the cleaned tweets. We then aggregate the scores hourly based on the time the tweets were posted online. Finally, we retrieve the Google search index of the word 'bitcoin' hourly for the same time period using the pytrends API. The hourly tweet counts, Google search index, averaged sentiment of tweets, and the value of Bitcoin in the last hour were used as the input features of the LSTM NN model while the Bitcoin value in the next hour was the target variable. During experimentation, the combination of hourly tweet count, the hourly average of tweet sentiment, and the value of Bitcoin in the last hour resulted in the lowest training and testing RMSE, \$296.33 and \$189.66, respectively.






% High frequency data have been mushrooming the financial market in recent years. There is a major need to quantify and predict such type of data in a tolerable lapse of time to minimize risk. In this dissertation, the Fast Fourier Transform is studied and implemented into conditional variance models in order to reduce the computa- tion time to estimate the parameters of such models. A study of the convolution sum is performed to determine the calculation advantage the fast Fourier transform ad- vocates over vectorise summation. The fast Fourier transform is implemented in the estimation of parameters of ARCH, GARCH and FIGARCH models, via their log- likelihood function. The speed-up factor was up to 4.0, 11.0 and 5.8 for the ARCH, GARCH and FIGARCH models respectively. A new approach to the problem which consists of a one-time analysis of the algorithm to improve the speed-up factor is pro- posed. We identify that larger sample sizes doesn’t imply greater computation time and smaller sample sizes doesn’t imply lower computation time. Optimal sample lengths are found via experimentation as no theory predicts the latter. By studying the behaviour of the fast Fourier transform algorithm we demonstrate that the new angle to the problem for a FIGARCH model was up to 4 times faster compared to the direct fast Fourier transform implementation. This is a global improvement for the calculation of convolution sum using fast Fourier transform and not just local to financial models.

\nocite{*}
\bibliographystyle{agsm}
\chapter*{Terms and Definitions}
\addcontentsline{toc}{section}{Terms and Definitions}
\begin{tabular}{l | l}
\(\alpha\) & Learning Rate \\
\(\eta\) & Reduced Learning Rate \\
\textbf{I} & Identity Matrix \\
\(\odot\)& Hadamard Product \\
NN & Neural Network \\
LSTM & Long Short-Term Memory \\
MSE & Mean Squared Error \\
MAE & Mean Absolute Error \\
NLP & Natural Language Processing \\
\end{tabular}

\newpage

\input{CHAPTER_1/CHAPTER 1.tex}
\input{CHAPTER_2/CHAPTER 2.tex}
\input{CHAPTER_3/CHAPTER 3.tex}
\input{CHAPTER_4/CHAPTER 4.tex}
\input{CHAPTER_5/CHAPTER 5.tex}
\input{CHAPTER_6/CHAPTER 6.tex}
\bibliography{REFERENCES}
%\input{PLACEHOLDER_TO_BE_DELETED/TO BE DELETED.tex}
\end{document}